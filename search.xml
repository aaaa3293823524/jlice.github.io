<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[快速幂取余算法]]></title>
    <url>%2Fp%2F7tbs7%2F</url>
    <content type="text"><![CDATA[计算a的b次方模m： a^b\ \%\ m暴力的做法是将a乘b次，最后对m取模。不过，这样可能导致溢出，时间复杂度也很高。 现在考虑，求3的10次方，最少需要做几次乘法运算。 很显然，当计算完3×3后，可以将结果“缓存”起来，后面计算3×3就不需要计算了，直接用“缓存”的结果即可。再之后也是利用同样的思路进行计算，这样可以减少需要进行的乘法计算的次数。显然，求3的10次方，最少需要做4次乘法运算。 设 $ f(b) $ 为计算 $ a^b $ 最少需要做的乘法运算次数，显然: f(1) = 0, f(2) = 1 \\ f(2x) = f(x) + 1 \\ f(2x+1) = f(2x) + 1其中，$ x $ 为正整数。 对于求大数余数的问题，同余模定理是很常用的： (a + b) \% c = (a \% c + b \% c) \% c(a × b) \% c = (a \% c × b \% c) \% c由上面的思路，就可以得到快速幂取余算法: 123456789int qmi(int a, int b, int m) &#123; int r = 1 % m; while (b) &#123; if (b &amp; 1) r = r * a % m; a = a * a % m; b &gt;&gt;= 1; &#125; return r;&#125; 按照这样的思路，由于乘法可以看成是多次加法，所以，也可以利用快速幂取余算法的思想计算两个大整数相乘取余。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并查集初步]]></title>
    <url>%2Fp%2F7ta3x%2F</url>
    <content type="text"><![CDATA[引言有若干节点，并将其中一些节点对进行连接，要判断任意两个节点是否连通（有路径到达，而不要求直接连接），连通后就不会断开连通关系，此时就可以使用并查集。并查集擅长动态维护许多具有传递性的关系，能在无向图中维护节点之间的连通性。 要判断两个节点是否连通，可以把连通的节点加入到各自的集合里，也就是，同一个集合里的节点都是连通的，不同集合里的节点是不连通的。 如图，节点a、b、c、d属于同一个集合，它们之间是连通的；节点x、y、z属于同一个集合，它们之间也是连通的。但是，不同集合里的节点，如b和x，是不连通的。 可以发现，每个集合构成了树形的结构，同一个集合里的节点，它们的根节点是相同的。要判断两个节点是否连通，只需要判断它们的根节点是否一致即可。 并查集的API定义： 1234567891011class UF &#123;public: // 查找节点的根节点 int find(int x) &#123;&#125;; // 连接节点p和q void join(int x, int y) &#123;&#125;; // 判断两个节点是否连通 bool isConnected(int x, int y) &#123; return find(x) == find(y); &#125;;&#125;; 实现并查集的存储结构可以使用数组或链表，一般采用数组作为实现的方式。数组记录元素的父节点。例如，A[i] = j，表示节点i的父节点是节点j。 初始时，每个节点各自作为一个集合，也就是节点的父节点是自身。 12345678private: vector&lt;int&gt; parent;public: UF(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; parent.push_back(i); &#125; &#125; 查找节点的根节点时，如果节点的父节点是自身，那么该节点就是根节点。否则，顺着父节点不断向上找，直至根节点。 123int find(int x) &#123; return parent[x] == x ? x : find(parent[x]);&#125; 连接两个节点时，实际上就是把两个节点的所在的集合合并成一个。首先需要找到两个节点的根节点，把其中一个根节点的父节点修改为另一个根节点。 123void join(int x, int y) &#123; parent[find(x)] = find(y);&#125; 路径压缩对于 find 的过程，可以修改节点的父节点来加速下次查找，这个优化称为“路径压缩”。 例如，在查找根节点的过程中，修改沿途节点的父节点为根节点： 123int find(int x) &#123; return parent[x] == x ? x : parent[x] = find(parent[x]);&#125; 非递归的写法： 12345678910111213int find(int x) &#123; int root = x; while (parent[root] != root) &#123; root = parent[root]; &#125; int tmp; while (x != root) &#123; tmp = parent[x]; parent[x] = root; x = tmp; &#125; return x;&#125; 还有其它的路径压缩方式。例如，在查找根节点的过程中，若节点不是根节点，就将节点的父节点修改为爷节点（父节点的父节点）： 1234567int find(int x) &#123; while (parent[x] != x) &#123; parent[x] = parent[parent[x]]; x = parent[x]; &#125; return x;&#125; 合并策略对于 join 的过程，如果不加任何策略合并，可能会形成很长的路径，应该尽量选择深度更小的集合的根节点进行父节点的修改。 按秩合并集合的秩，也就是集合所对应的树的深度。 如果两个集合的秩不相等，就把秩小的集合的根节点的父节点修改为秩大的集合的根节点。如果两个集合的秩相等，那么，将其中一个集合的根节点的父节点修改为另一个集合的根节点，同时，将未修改父节点的根节点的集合的秩+1。 123456789101112131415161718192021222324252627class UF &#123;private: vector&lt;int&gt; parent; vector&lt;int&gt; rank;public: UF(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; parent.push_back(i); rank.push_back(1); &#125; &#125; void join(int x, int y) &#123; int xRoot = find(x); int yRoot = find(y); if (xRoot != yRoot) &#123; if (rank[xRoot] &gt; rank[yRoot]) &#123; parent[yRoot] = xRoot; &#125; else &#123; parent[xRoot] = yRoot; if (rank[xRoot] == rank[yRoot]) &#123; rank[yRoot]++; &#125; &#125; &#125; &#125; ... 也可以在根节点存储秩的信息，思路参考下面的“按size合并” 按size合并为了记录集合的size，也就是集合包含节点的个数，可以将根节点的父节点的值修改为“-1*集合包含节点的个数”，同时，根节点的判断方式修改为父节点的值小于0。合并时，将节点数少的集合并入节点数多的集合，也就是修改节点数少的集合的根节点的父节点为节点数多的集合的根节点。注意，在修改父节点前要更新节点数多的集合的节点数。 12345678910111213141516171819202122232425262728class UF &#123;private: vector&lt;int&gt; parent;public: UF(int n) &#123; for (int i = 0; i &lt; n; i++) &#123; parent.push_back(-1); &#125; &#125; int find(int x) &#123; return parent[x] &lt; 0 ? x : parent[x] = find(parent[x]); &#125; void join(int x, int y) &#123; int xRoot = find(x); int yRoot = find(y); if (xRoot != yRoot) &#123; if (parent[xRoot] &lt; parent[yRoot]) &#123; parent[xRoot] += parent[yRoot]; parent[yRoot] = xRoot; &#125; else &#123; parent[yRoot] += parent[xRoot]; parent[xRoot] = yRoot; &#125; &#125; &#125; ... 不过，按size合并的策略并不总能选择深度更小的集合的根节点进行父节点的修改，例如本文第一个图的情况。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Deepin桌面下Office图标显示为压缩包]]></title>
    <url>%2Fp%2F7t7af%2F</url>
    <content type="text"><![CDATA[在使用ArchLinux系的系统（比如我用的Manjaro），使用Deepin桌面时，Office图标会显示为压缩包： 虽然说，docx、xlsx、pptx格式其实也就是zip包，但图标错乱还是会让强迫症的我感觉很难受。不过，在Xfce4桌面环境下是没有这个问题的，Office图标正确显示为Office图标，但Deepin下就有这种问题，有点奇怪。 究其原因，和WPS有关。在参考了帖子： .xlsx and .docx files are opened as zip file - Technical Issues and Assistance / Applications - Manjaro Linux Forum (Deepin) .docx shown as .zip (icon) - Support for Community Editions - Manjaro Linux Forum After Installing WPS-Office Office Icons Change - Technical Issues and Assistance / Applications - Manjaro Linux Forum 然后，终于找到了解决方案： 12$ sudo rm /usr/share/mime/packages/wps-office-*.xml$ sudo update-mime-database /usr/share/mime 弄完之后，Office图标就恢复正常了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《实战Java高并发程序设计》读书笔记]]></title>
    <url>%2Fp%2F7t3gc%2F</url>
    <content type="text"><![CDATA[这两天快速看了下《实战Java高并发程序设计》这本书，对Java高并发程序有一个初步的认识。 这本书是在iPad上用MarginNotes 3看的，只是做了些笔记，还没进行代码实践，后续还需要细化。 基础概念并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的，而并行是真正意义上的“同时执行”。 临界区用来表示一种公共资源或者说共享数据，可以被多个线程使用。但是每一次， 只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源就必须等待。 原子性是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作旦开始，就不会被其他线程干扰。 指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。 关键字 volatile 并不能代替锁，它也无法保证一些复合操作的原子性。关键字 volatile 也能保证数据的可见性和有序性。 当一个Java应用内只有守护线程时，Java虚拟机就会自然退出。 关键字 synchronized 的作用是实现线程间的同步。它的工作是对同步的代码加锁，使得每一次，只能有一个线程进入同步块，从而保证线程间的安全性。 JDK并发包重入锁 使用 java.util.concurrent.locks.ReentrantLock 类来实现 重入锁有着显示的操作过程。开发人员必须手动指定何时加锁，何时释放锁。 一个线程连续两次获得同一把锁是允许的 如果同一个线程多次获得锁，那么在释放锁的时候，也必须释放相同次数。 如果释放锁的次数多了，那么会得到一个 java.lang.IllegaMonitorStateException 异常 如果释放锁的次数少了，那么相当于线程还持有这个锁，因此，其他线程也无法进入临界区。 lockInterruptibly()是一个可以对中断进行响应的锁申请动作，即在等待锁的过程中，可以响应中断。 使用 tryLock() 方法进行一次限时的等待。 重入锁允许对其公平性进行设置，公平锁的实现成本比较高，性能却非常低下: 1public ReentrantLock(boolean fair) 利用 Condition 对象， 可以让线程在合适的时间等待，或者在某一个特定的时刻得到通知，继续执行。 信号量(Semaphore)：信号量可以指定多个线程，同时访问某一个资源 ReadwriteLock是读写分离锁。可以有效地帮助减少锁竞争提升系统性能。 倒计数器: CountdownLatch 循环栅栏: CyclicBarrier CyclicBarrier 可以接收一个参数作为 barrierAction 就是当计数器一次计数完成后，系统会执行的动作。 LockSupport是一个非常方便实用的线程阻塞工具，它可以在线程内任意位置让线程阻塞。 更为一般化的限流算法有两种:漏桶算法和令牌桶算法。 在使用线程池后，创建线程变成了从线程池获得空闲线程，关闭线程变成了向线程池归还线程 Executor框架 newFixedThreadPool() 方法:该方法返回一个固定线程数量的线程池。 newSingleThreadExecutor() 方法:该方法返回一个只有一个线程的线程池。 newCachedThreadPool() 方法:该方法返回一个可根据实际情况调整线程数量的线程池 newSingleThreadScheduledExecutor() 方法: 扩展了在给定时间执行某任务的功能 newScheduledThreadPool() 方法: 可以指定线程数量。 核心线程池的内部实现：都只是 Threadpoolexecutor 类的封装 拒绝策略 自定义线程创建: ThreadFactory ThreadPoolExecutor 是一个可以扩展的线程池。它提供了beforeExecute()、afterExecute()、terminaerd() 三个接口用来对线程池进行控制。 除JDK内置的线程池以外，Guava 对线程池也进行了一定的扩展 DirectExecutor线程池总是将任务在当前线程中直接执行 将普通线程池转为Daemon线程池的方法 MoreExecutors.getExitingExecutorService() 并发集合ConcurrentHashMap：这是一个高效的并发 Hashmap CopyOnWriteArrayList: 在读多写少的场合，这个List的性能非常好，远远优于 Vector。读取是完全不用加锁的， 写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。 ConcurrentLinkedQueue：高效的并发队列 BlockingQueue 表示阻塞队列，非常适合作为数据共享的通道。BlockingQueue 让服务线程在队列为空时进行等待，当有新的消息进入队列后，自动将线程唤醒 ConcurrentSkipListMap：跳表的实现。 JMH (Java Microbenchmark Harness) 专门用于性能测试的框架，其精度可以到达毫秒级。 Mode表示JMH的测量方式和角度 迭代是JMH的一次测量单位 通过 State可以指定一个对象的作用范围。JMH中的 State可以理解为变量或者数据模型的作用域，通常包括整个 Benchmark级别和 Thread线程级别。 锁的优化减少锁持有时间 减小锁粒度。所谓减小锁粒度，就是指缩小锁定对象的范围，从而降低锁冲突的可能性，进而提高系统的并发能力 用读写分离锁来替换独占锁。在读多写少的场合使用读写锁可以有效提升系统的并发能力 锁分离 锁粗化 虚拟机在遇到一连串连续地对同一个锁不断进行请求和释放的操作时，便会把所有的锁操作整合成对锁的一次请求，从而减少对锁的请求同步的次数，这个操作叫作锁的粗化。 锁偏向锁偏向的核心思想是:如果一个线程获得了锁， 那么锁就进入偏向模式。当这个线程再次请求锁时，无须再做任何同步操作。使用Java虚拟机参数-XX:+UseBiasedLocking可以开启偏向锁。 轻量级锁使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 自旋锁让当前线程做几个空循环(这也是自旋的含义)， 如果还不能获得锁，才会真的将线程在操作系统层面挂起 锁消除Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竟争的锁。 逃逸分析观察某一个变量是否会逃出某一个作用域 Threadlocal ThreadLocal的实例代表了一个线程局部的变量，每条线程都只能看到自己的值，并不会意识到其它的线程中也存在该变量。 它采用采用空间来换取时间的方式，解决多线程中相同变量的访问冲突问题。为每一个线程分配不同的对象，需要在应用层面保证 ThreadLocal 只起到了简单的容器作用。ThreadLocalMap 是定义在 Thread 内部的成员，ThreadLocalMap的实现使用了弱引用。 无锁的策略使用一种叫作比较交换(CAS， Compare And Swap)的技术来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止。 CAS算法的过程是:它包含三个参数CAS(VE，N)，其中V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果值和E值不同， 说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS返回当前V的真实值。 JDK并发包中有一个atomic包，里面实现了一些直接使用CAS操作的线程安全的类型。 Atomicinteger 是可变的，并且是线程安全的。Unsafe类就是封装了一些类似指针的操作 Atomicreference 可以保证在修改对象引用时的线程安全性 Atomicstampedreference 内部不仅维护了对象值，还维护了一个时间 Atomiclntegerarray， Atomiclong Array 和 Atomicreferencearray 让普通变量也享受原子操作: Atomiclntegerfieldupdater 死锁哲学家就餐问题 并行模式与算法【单例模式】 1234567891011public class StaticSingleton &#123; private StaticSingleton() &#123; System.out.println("StaticSingleton is create"); &#125; private static class SingletonHolder &#123; private static StaticSingleton instance = new StaticSingleton(); &#125; public static StaticSingleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 不变模式 对属性的final定义确保所有数据只能在对象被构造时赋值1次。之后，就永远不发生改变。 对class的final确保了类不会有子类 【生产者-消费者模式】 生产者-消费者模式中的内存缓冲区的主要功能是数据在多线程间的共享，此外，通过该缓冲区，可以缓解生产者和消费者间的性能差。 BlockigQueue 充当了共享内存缓冲区，用于维护任务或数据队列 Disruptor 框架使用无锁的方式实现了一个环形队列，非常适合实现生产者-消费者模式 消费者监控冲区中的信息策略由 WaitStrategy 接口进行封装， 当两个变量存放在一个缓存行时，在多线程访问中，可能会影响彼此的性能。 Future模式 Future 模式的核心思想是异步调用 并行流水线 执行过程中有数据相关性的运算都是无法完美并行化的 并行搜索 并行排序 奇偶交换排序 希尔排序 矩阵乘法 将矩阵A进行水平分割，得到子矩阵A1和A2，矩阵B进行垂直分割，得到子矩阵B1和B2。再将结果进行拼接就能得到原始矩阵A和B的乘积。 网络NIO AIO Java新特性在Java8中，使用 default关键字可以在接口内定义实例方法 函数式接口就是只定义了单一抽象方法的接口 方法引用使用 :: 定义， :: 的前半部分表示类名或者实例名，后半部分表示方法名称。如果是构造函数，则使用new表示。 parallel() 方法得到一个并行流 集合对象并行化可以使用 parallelStream() 函数 Arrays.parallelSort() 方法直接使用并行排序 新版本的 ConcurrentHashMap 增加了一些foreach操作、reduce操作、computeIfAbsent()、search操作 newKeySet() 方法返回一个线程安全的Set 在反应式编程中，核心的两个组件是Publisher和Subscriber。Publisher将数据发布到流中， Subsciber则负责处理这些数据]]></content>
  </entry>
  <entry>
    <title><![CDATA[拼多多2020实习笔试题题解]]></title>
    <url>%2Fp%2F7szz3%2F</url>
    <content type="text"><![CDATA[题解是交卷后做的，不保证AC。 题目1题目描述 给出长虔都为n的两个整数数组a[n]和b[n]，特殊运算 S = a[0]*b[0] + … + a[n-1]*b[n-1]，你可以改变a数组的顺序使得运算S得到的值最小，给出最终的最小值。数组长度n大于50，对于每个元素X，0&lt;=X&lt;=100。 输入描述 输入一共三行。第一行为n，表示两个数组的长度。第二行包括n个数字，用空格隔开，是a数组的值。第三行包括n个数字，用空格隔幵，是b数组的值。 输出描述 输出一行，包含一个数字，表示最小的S值。 示例1 输入 12331 1 310 30 20 输出 180 题解水题。先对数组a、b排序，一个升序遍历一个降序遍历。 代码： 1234567n = int(input())a = sorted(list(map(int, input().split())))b = sorted(list(map(int, input().split())), reverse=True)res = 0for i in range(n): res += a[i] * b[i]print(res) 题目2题目描述 小明给儿子小小明买了一套英文字母卡片（总共包合52张，区分大小写）,小小明把卡片丢在地上玩耍，并从中取出若干张排成一排，形成了一个卡片序列。此时．小明需要将卡片序列中的重复字母剔除（同一个字母的大小写只保留一个）。请问，所有可能的结果中，字母序最小（不区分大小写）的序列的第一张卡片上是哪个字母？ 输入描述 一行输入，包合一个非空字符串，表示卡片序列，长度为 N（1＜=N＜=52）。 输出描述 一行输出，包合一个字母（如果结果是大写字母，则需要转成小写）。 示例1 输入 1xaBXY 输出 1a 说明 剔除完后的结果为abxy 题解这道题题意比较绕。大意就是，52个字母中的若干个组成的一个序列，对于每对重复字母（不区分大小写），都剔除其中一个，由于剔除的位置不同，处理后的序列有多种情况，从中找到字母序最小的，返回其首字母。 例如，xaBXY，其中x重复出现，剔除其中一个x，有两种情况：aBXY、xaBY，前者的字母序最小，所以返回其首字母a。又如，bBa，有两种情况：Ba、ba，两者不区分大小写是一样的，首字母是b。又如，cDadC，字母序最小的序列是adC，返回a。 理清楚题意后，解决起来就比较简单。考虑哪些字母可能成为序列的首字母。从左往右扫描，如果遇到只出现一次的字母，由于该字母不会被剔除，所以其后的字母将不会成为首字母，将该字母加入待选首字母并结束扫描；如果遇到出现两次的字母，若第一次遇到该字母，则将该字母加入待选并继续扫描，但若第二次遇到该字母，就需要停止扫描了，因为如果剔除前一个该字母，则当前位置的该字母将会被保留，所以其后的字母将不会成为首字母。 代码： 1234567891011121314151617from collections import Counters = input().lower()cnt = Counter(list(s))rec = set()heads = []for c in s: if cnt[c] == 1: heads.append(c) break else: if c in rec: break else: heads.append(c) rec.add(c)print(min(heads)) 题目3题目描述 小镇沿街分布（可以理解为都在数轴上），有n家银行（位置以数轴的坐标表示，金额表示可以被抢走的金额），两个绑匪试图分别抢劫一个银行，为了让警方多奔波他们商定选择的两个银行距离不小于d，请问符合约定的情况下他们能抢到的总金额最大是多少？ 输入描述 输入包括 n+1 行。第一行包含两个数字n和d（1&lt;=n&lt;=200000，1&lt;=d&lt;=100000000)，n表示银行的数量，d表示约定的距离。下面n行，每一行包括两个数字a, b（1&lt;=a,b&lt;=100000000），分别表示坐标和金额，空格分隔。 输出描述 输出一个数字，表示可以获得的最大金额。 示例1 输入 12345676 31 13 54 86 410 311 2 输出 111 题解首先，需要对银行按位置排序。对于每家银行，找到其右侧符合距离限制的金额最大值。 由于每次都需要某位置及其右侧的金额最大值，不妨先计算出来，存为后缀max数组。然后，对于每家银行，找到其右侧符合距离限制且最近的银行，取其后缀max数组的值，即右侧银行可获得的最大金额，并更新可获得的最大金额。 代码： 123456789101112131415161718192021222324252627282930#include&lt;bits/stdc++.h&gt;using namespace std;int main() &#123; int n, d; cin &gt;&gt; n &gt;&gt; d; vector&lt;pair&lt;int, int&gt; &gt; banks(n, make_pair(0, 0)); for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; banks[i].first &gt;&gt; banks[i].second; &#125; sort(banks.begin(), banks.end(), [](pair&lt;int, int&gt; a, pair&lt;int, int&gt; b) &#123; return a.first &lt; b.first; &#125;); vector&lt;int&gt; rmax(n, banks.back().second); for (int i = n - 2; i &gt;= 0; i--) &#123; rmax[i] = max(banks[i].second, rmax[i+1]); &#125; int res = 0; for (int i = 0; i &lt; n - 1; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; if (banks[j].first - banks[i].first &gt;= d) &#123; res = max(res, banks[i].second + rmax[j]); break; &#125; &#125; &#125; cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; 题目4题目描述 一个合法的圆括号表达式满足一下条件：1．””空字符串被认为是合法的2．如果字符串”X”与”Y”是合法的，则”XY”也被认为是合法的3．如果字符串”X”是合法的，则”(X)”也是合法的例子：””, “()”, “()()”, “(())”这些都是合法的现给出两个不保证合法的由圆括号组成的字符串，你需要交错这两个圆括号序列（在组成的新字符串中，每个初始字符串都保持原来的顺序）得到一个新的合法的圆括号表达式（不同的交错方式可能会得到相同的表达式，这种情况分开计数），求共有多少结果合法的交错方式（无法得到合法的圆括号表达式则输出0），输出结果模 10^9+7 的值(^符号是乘方的意思） 输入描述 输入包括两行，分别是两个只有”(和”)”组成的字符串，长度小于2500 输出描述 输出为一个数字，表示合法的交错方式数量模上10^9+7的结果 示例1 输入 12(()()) 输出 119 题解好吧，不会。。。]]></content>
      <tags>
        <tag>刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[N-sum问题通解]]></title>
    <url>%2Fp%2F7qvfi%2F</url>
    <content type="text"><![CDATA[N-sum 问题还是比较典型的，这里进行一下小结。 首先描述一下 N-sum 问题：有一个数组 nums，要求从数组中选择 n 个数，使得这些数的和恰好为 target ，输出所有不重复的可行组合。 如果采用暴力解法，显然时间复杂度为 $O(N^n)$，这一般是不可取的。 下面是 N-sum 问题的LeeCode链接： 1. Two Sum 15. 3Sum 18. 4Sum Two-Sum先来解决Two-Sum问题，这是N-sum问题的基础。如果我们能把Two-Sum的时间复杂度降为 $O(N)$ ，然后就能把N-sum的时间复杂度降为 $O(N^{n-1})$ 了。 如果采用暴力解法，每次选择一个数时，都要遍历数组来选择另一个数，并判断和是否为 target，这样显然是低效的。当我们选择一个数 x 时，我们希望数组里有一个数为 target - x。为了快速判断数组里是否有某个数，可以用 HashSet。但是，这样存在问题，因为数组里可能有重复的数，当 x 等于 target - x 时，这种做法就错了。因此，正确的做法应该是用 HashMap，用来存储各个数还有多少可用。 双指针法另一种解法是使用“双指针”，这种解法要求 nums 是有序的。例如，nums 为 [1, 2, 4, 7, 13, 16]，target 为 15。初始时，指针p、q位于两端： 如果p、q所指向的值之和大于 target，那么q往左移，这是因为q左侧的值比q所指的值小，所以q往左移能使得之和变小；如果之和小于 target，那么p往右移，这是因为p右侧的值比p所指的值大，所以p往右移能使得之和变大；如果之和等于 target，那么p往右移且q往左移（有点像夹挤），这个稍微有点难理解，这也是“双指针”法的思想精髓。首先，如果p往左移或q往右移，其实就回到了之前的状态；其次，如果只是p往右移，显然之和会大于 target，如果只是q往左移，显然之和会小于 target；于是乎，p往右移且q往左移。 然后就是考虑如何判断可行组合是否重复。由于数组是有序的，可行组合的加入也是有序的，因此，只需判断当前可行组合与最后一个已加入的可行组合是否重复即可。 代码1234567891011121314151617vector&lt;vector&lt;int&gt;&gt; twoSum(vector&lt;int&gt;&amp; nums, int target, int st, int ed) &#123; vector&lt;vector&lt;int&gt; &gt; res; while (st &lt; ed) &#123; if (nums[st] + nums[ed] == target) &#123; if (res.empty() || res.back()[0] != nums[st]) &#123; res.push_back(vector&lt;int&gt;&#123;nums[st], nums[ed]&#125;); &#125; ++st; --ed; &#125; else if (nums[st] + nums[ed] &gt; target) &#123; --ed; &#125; else &#123; ++st; &#125; &#125; return res;&#125; N-Sum问题转化对于 N-sum 问题，外面几层其实就是暴力遍历，只有最后两个数转为 Two-Sum 问题，使用双指针法求解。这种做法，其实就相当于把时间复杂度降了一阶。 例如，对于 3-Sum 问题，先从有序数组 nums 中取一个数（遍历），然后从该数右侧的数里再取两个数（Two-Sum）；对于 4-Sum 问题，先从有序数组 nums 中取两个数（遍历），然后从这两个数的右侧里再取两个数（Two-Sum）。可见，4-Sum 只是比 3-Sum 多了一层循环。为了控制循环层数，可以使用递归。 代码1234567891011121314151617181920vector&lt;vector&lt;int&gt;&gt; nSum(vector&lt;int&gt;&amp; nums, int target, int st, int ed, int n) &#123; vector&lt;vector&lt;int&gt; &gt; res; if (n == 2) &#123; return twoSum(nums, target, st, ed); &#125; else &#123; for (int i=st; i&lt;=ed; ++i) &#123; int num = nums[i]; if (res.empty() || res.back()[0] != num) &#123; auto ret = nSum(nums, target-num, i+1, nums.size()-1, n-1); for (auto r : ret) &#123; vector&lt;int&gt; tmp; tmp.push_back(num); tmp.insert(tmp.end(), r.begin(), r.end()); res.push_back(tmp); &#125; &#125; &#125; return res; &#125;&#125; “双指针”的想法还是比较巧妙的，如果没见过，还真的不容易想出来。所以，练习是有必要的，也需要进行归纳总结。]]></content>
      <tags>
        <tag>刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求单链表交点]]></title>
    <url>%2Fp%2F7qhfm%2F</url>
    <content type="text"><![CDATA[题目今天面试时，面试官问了这样一个问题：两个单链表相交，怎么求交点。所谓相交，就是两个节点的next指针相同。 简单解法一个简单的思路是：分别遍历这两个链表，并将这两个链表的节点分别保存到两个列表里，然后同步逆序遍历这两个列表，当出现不相同的元素时，则下一个元素就是这两个链表的交点。 例如，对于上图的两个单链表，遍历上面的单链表得到列表：A, B, C, D, E, F, G；遍历下面的单链表得到列表：H, I, E, F, G。因为单链表相交之后就汇合了，汇合之后的节点就是一样的，而汇合之前的节点不一样，所以同步逆序遍历这两个列表：G-G, F-F, E-E, D-I……于是，E节点就是交点。 这种做法时间复杂度为O(n)，但空间复杂度为O(n)，有没有空间复杂度更低的解法呢？ 如果使用HashMap存储，先遍历上面的单链表，并把节点存储到HashMap里，然后遍历下面的单链表，每次都看当前节点是否已经存在于HashMap中，如果存在，则该节点就是交点。采用这种做法，不必把两个单链表都遍历完，不过依然没有降低空间复杂度。 另一种思路是暴力法，也就是遍历这两个链表，判断第一个链表的每个节点是否在第二个链表中，这种做法的时间复杂度为O(n^2)。 优雅解法这个问题比较麻烦的地方在于，这两个单链表相交之前的部分的长度可能不一致。假如这两个单链表长度一致，那么指针p、q只要同步移动，然后首次相遇的地方就是交点了。 例如，对于图中的两个单链表，假如上面的单链表没有A, B节点，指针p初始指向C节点，那么，指针p、q只要同步移动两次，就会在节点E相遇，E节点就是交点。那么，我们要怎么样让指针p指向C节点后，指针p、q才同步移动呢？ 其实很简单，先遍历一下这两个单链表，得到它们的长度，然后让长的单链表的指针先走长度之差步，就可以了！对于图中的两个单链表，上面的单链表长度为7，下面的单链表长度为5，两个单链表的长度之差为2，且上面的单链表更长，那么就让指针p先走2步（这样就到了C节点），然后指针p、q同步移动即可。 扩展问题如何判断两个单链表是否相交这个问题比较简单。显然，如果两个单链表相交，则必然是“Y”形的，而不是“X”形的。只需要判断两个单链表中是否存在相同的元素即可。 如果这两个单链表相交，则尾节点必然相同，因此，直接遍历到尾节点，然后判断尾节点是否相同即可。还可以把节点存到哈希表，在遍历第二个单链表时，判断节点是否在哈希表中已存在，若已存在则相交。 如何判断单链表里是否有环 这个可以采用快慢指针的技巧。初始时，指针p、q都位于初始节点，然后每次指针p移动一个节点，指针q移动两个节点，则指针p、q必然在环内相遇。 为什么指针p、q必然在环内相遇呢？这是因为在环内，可以看成是指针q“追赶”指针p，每次“追赶”1一个节点（也就是相对距离-1），所以必然能相遇。而且，指针p、q相遇时，指针p在环内走过的距离不会超过环的长度。 LeetCode: 141. Linked List Cycle 如何求单链表的环的长度很简单：根据上一个问题可以知道一个处于环内的节点，固定指针q，然后继续移动指针p（指针p每次移动一个节点），当指针p、q再次相遇时，指针p继续移动的次数就是环的长度。 如何求单链表中第一个在环里的节点 假设单链表起点到第一个在环里的节点的距离为n，快慢指针p、q在环内相遇，第一个在环里的节点到相遇点的距离为f，环的长度为L。 那么，显然，指针p、q相遇时，指针p走过的距离为n+f，指针q走过的距离为n+f+xL（之所以是xL是因为，假如n较大而L较小，那么指针q可能在环内转了好几圈才和指针p相遇）。显然有： 2(n+f) = n+f+xL故 n = xL-f, x>0，或者写为： n = L - f + xL \quad x\geq0而指针p、q的相遇点到第一个在环里的节点的距离为L-f。指针p从单链表的起点开始移动，每次移动1个节点，指针q从相遇点开始移动，每次也移动1个节点，那么，指针p、q就会在第一个在环里的节点处相遇。 LeetCode: 142. Linked List Cycle II 特殊解法 对于本文最开始的问题，还有一种比较特殊的解法。先遍历其中一个链表，遍历到尾节点时，将尾节点的next指针指向另一个链表的起点，然后，问题就转化为求单链表中第一个在环里的节点了。 后记： 在LeetCode上刷到了原题：160. Intersection of Two Linked Lists，还是要多刷题啊！]]></content>
      <tags>
        <tag>刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memset的一个坑]]></title>
    <url>%2Fp%2F7qghk%2F</url>
    <content type="text"><![CDATA[为数组赋初值是很常见的操作，如果不赋初值，默认就是随机值： 1234int main() &#123; int a[5]; return 0;&#125; 如果想将a中的元素全部赋为0，第2行可以写为： 1int a[5]&#123;0&#125;; 这是C++ 11的写法，在此之前应写为： 1int a[5] = &#123;0&#125;; 如果想把第0个元素赋为1，其余赋为0呢，那么可以写为： 1int a[5]&#123;1&#125;; 注意这里并不是把数组的元素全部设为1。 如果把数组定义为全局变量，那么会在堆中创建，会初始化为默认值： 1234int a[5];int main() &#123; return 0;&#125; 此时数组a的元素会全部初始化为0。 如果想把数组重置为全0，那么可以用memset： 1memset(a, 0, sizeof a); 那么，怎么把数组里所有元素全部赋初值1呢？ 一个很容易犯的错误写法就是： 1memset(a, 1, sizeof a); 若如此做，a中的元素都是16843009。为什么会这样呢？ 这是memset的函数原型： 1void *memset(void *s, int c, size_t n); 其实memset是给字节数组赋初值的！memset会对s 逐字节填充 值c。由于int有4字节，所以上面那个错误写法导致每个元素被写为： 10x01010101 转为十进制也就是16843009。 所以，还是用循环吧……这时，有点怀念Python的给list赋初值的写法： 1a = [1] * 5 不过，别用list赋初值，因为是浅拷贝： 1234&gt;&gt;&gt; a = [[]] * 5&gt;&gt;&gt; a[0].append(3)&gt;&gt;&gt; a[[3], [3], [3], [3], [3]]]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解Minimax算法与α-β剪枝]]></title>
    <url>%2Fp%2F7q6ye%2F</url>
    <content type="text"><![CDATA[在局面确定的双人对弈里，常采用博弈树搜索。我方追求更大的赢面，而对方会设法降低我方的赢面。由于局面确定，因此可以对赢面进行评估。我方往较大赢面的方向走，同时考虑对方的走法。由于对方的走法不确定，就假设对方会选择最大程度降低我方赢面的方向走，我方应规避那些对方可以大幅降低我方赢面的走法。 Minimax算法称我方为MAX，对方为MIN，图示如下： 例如，对于如下的局势，假设从左往右搜索，根节点的数值为我方赢面（倒推值）： 我方应选择中间的路线。因为，如果选择左边的路线，最差的赢面是3；如果选择中间的路线，最差的赢面是15；如果选择右边的路线，最差的赢面是1。虽然选择右边的路线可能有22的赢面，但对方也可能使我方只有1的赢面，假设对方会选择使得我方赢面最小的方向走，那么经过权衡，显然选择中间的路线更为稳妥。 实际上，在看右边的路线时，当发现赢面可能为1就不必再去看赢面为12、20、22的分支了，因为已经可以确定右边的路线不是最好的。这个过程就是剪枝，可以避免不必要的计算。 $\alpha-\beta$ 剪枝例如，对于如下的局势，假设从左往右搜索： 若已知某节点的所有子节点的倒推值，则可以算出该节点的倒推值：对于MAX节点，取最大倒推值；对于MIN节点，取最小倒推值。 若已知某节点的部分子节点的倒推值，虽然不能算出该节点的倒推值，但可以算出该节点的倒推值的取值范围。同时，利用该节点的倒推值的取值范围，在搜素其子节点时，如果已经确定没有更好的走法，就不必再搜索剩余的子节点了。 记 $v$ 为节点的倒推值，且 $\alpha \leq v \leq \beta$，即 $\alpha$ 为最大下界， $\beta$ 为最小上界。当 $\alpha \geq \beta$ 时，该节点剩余的分支就不必继续搜索了（也就是可以进行剪枝了）。注意，当 $\alpha = \beta$ 时，也可以剪枝，这是因为不会有更好的结果了，但可能有更差的结果。 初始化时，令 $\alpha = -\infty$ ，$\beta = +\infty$ ，也就是 $-\infty \leq v \leq +\infty$。到节点A时，由于左子节点的倒推值为3，而节点A是MIN节点，试图找倒推值小的走法，于是将 $\beta$ 值修改为3，这是因为3小于当前的 $\beta$ 值（$\beta = +\infty$）。然后节点A的右子节点的倒推值为17，此时不修改节点A的 $\beta$ 值，这是因为17大于当前的 $\beta$ 值（$\beta = 3$）。之后，节点A的所有子节点搜索完毕，即可计算出节点A的倒推值为3。 节点A是节点B的子节点，计算出节点A的倒推值后，可以更新节点B的倒推值范围（也就是 $\alpha$ 和 $\beta$ 值）。由于节点B是MAX节点，试图找倒推值大的走法，于是将 $\alpha$ 值修改为3，这是因为3大于当前的 $\alpha$值（$\alpha = +\infty$）。之后搜索节点B的右子节点C，并将节点B的 $\alpha$ 和 $\beta$ 值传递给节点C。 对于节点C，由于左子节点的倒推值为2，而节点C是MIN节点，于是将 $\beta$值修改为2。此时 $\alpha \geq \beta$，故节点C的剩余子节点就不必搜索了，因为可以确定，通过节点C并没有更好的走法。然后，节点C是MIN节点，将节点C的倒推值设为 $\beta$ ，也就是2。由于节点B的所有子节点搜索完毕，即可计算出节点B的倒推值为3。 计算出节点B的倒推值后，节点B是节点D的一个子节点，故可以更新节点D的倒推值范围。由于节点D是MIN节点，于是将 $\beta$ 值修改为3。然后节点D将 $\alpha$ 和 $\beta$ 值传递给节点E，节点E又传递给节点F。对于节点F，它只有一个倒推值为15的子节点，由于15大于当前的 $\beta$ 值，而节点F为MIN节点，所以不更新其 $\beta$ 值，然后可以计算出节点F的倒推值为15。 计算出节点F的倒推值后，节点F是节点E的一个子节点，故可以更新节点E的倒推值范围。节点E是MAX节点，更新 $\alpha$，此时 $\alpha \geq \beta$，故可以剪去节点E的余下分支。然后，节点E是MAX节点，将节点E的倒推值设为 $\alpha$ ，也就是15。此时，节点D的所有子节点搜索完毕，即可计算出节点D的倒推值为3。 计算出节点D的倒推值后，节点D是节点H的一个子节点，故可以更新节点H的倒推值范围。节点H是MAX节点，更新 $\alpha$。然后，按搜索顺序，将节点H的 $\alpha$ 和 $\beta$ 值依次传递给节点I、J、K。对于节点K，其左子节点的倒推值为2，而节点K是MIN节点，更新 $\beta$，此时 $\alpha \geq \beta$，故可以剪去节点K的余下分支。然后，将节点K的倒推值设为2。 计算出节点K的倒推值后，节点K是节点J的一个子节点，故可以更新节点J的倒推值范围。节点J是MAX节点，更新 $\alpha$，但是，由于节点K的倒推值小于 $\alpha$，所以节点J的 $\alpha$ 值维持3保持不变。然后，将节点J的$\alpha$ 和 $\beta$ 值传递给节点L。由于节点L是MIN节点，更新 $\beta = 3$，此时 $\alpha \geq \beta$，故可以剪去节点L的余下分支，由于节点L没有余下分支，所以此处并没有实际剪枝。然后，将节点L的倒推值设为3。 此时，节点J的搜索子节点搜索完毕，计算出节点J的倒推值为3。由于节点J是节点I的子节点，故可以更新节点I的倒推值范围。节点I是MIN节点，更新 $\beta = 3$，此时，$\alpha \geq \beta$，故可以剪去节点I的余下分支。然后，将节点I的倒推值设为3。 参考链接 CS 161 Recitation Notes - The Minimax Algorithm CS 161 Recitation Notes - Minimax with Alpha Beta Pruning]]></content>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下实用批处理脚本]]></title>
    <url>%2Fp%2F7q1p8%2F</url>
    <content type="text"><![CDATA[经常需要在Linux下批量处理图片，想了想，还是写个实用的批处理小脚本一劳永逸。 代码SRC为待处理目录；DST为目标目录，也就是保存处理后的文件的目录；SFX用于设置文件名后缀，如果为空就不修改文件名后缀。如果SRC有子目录，DST将和SRC有相同的子目录结构。脚本中的convert命令修改成相应的处理命令。 12345678910111213141516171819202122#!/bin/bashSRC=/path/to/sourceDST=/path/to/destinationSFX=jpgIFS_old=$IFSIFS=$'\n'for dir in $(find $SRC -type d)do mkdir -p $(echo $dir | sed "s|$SRC|$DST|")donefor file in $(find $SRC -type f)do new_file=$(echo $file | sed "s|$SRC|$DST|") if [[ -n $SFX ]]; then new_file=$&#123;new_file%.*&#125;.$SFX fi echo $file convert $file $new_filedoneIFS=$IFS_old 脚本讲解IFS是internal field separator的缩写，shell的特殊环境变量，默认是空白（空格、换行、制表符）。IFS=$&#39;\n&#39;设置分隔符为\n，这种写法不支持sh。之所以要设置IFS，是因为路径可能包含空格，在for循环时就会被截断。 使用sed进行替换时，不一定要使用/，也可以使用其它符号（如|、#等）。也就是，可以写成sed &#39;s/old/new/&#39;的形式，也可以写成sed &#39;s|old|new|&#39;的形式。在这里，由于路径中有/，为了方便，就是用|来替换sed命令中常使用的/。 sed默认使用BRE（基本正则表达式），如果要使用ERE（扩展正则表达式），需要加上-E参数。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ipv6 hosts]]></title>
    <url>%2Fp%2F7q0w4%2F</url>
    <content type="text"><![CDATA[一些校园网能使用ipv6，而Google、Youtube等网站支持ipv6。但是，DNS服务器一般返回的是ipv4的地址，因此，可以通过修改hosts来直接使用ipv6地址访问这些网站。 可以先在IPv6 连接测试来测试是否接入了ipv6。 在GitHub上有ipv6-hosts，用这个替换系统默认的hosts文件即可直接使用ipv6地址来访问这些网站。 然而，在使用过程中发现stackoverflow.com不能正常使用了，因此，需要删除stackoverflow.com相关条目，用ipv4访问stackoverflow.com就正常了。 写这篇文章主要是因为，前一段时间Youtube视频看不了了，通过浏览器开发者工具发现是googlevideo.com访问不了的原因，于是设置了下googlevideo.com相关的hosts。然后今天Youtube直接不能访问了，于是想了想，还是写一个自动更新hosts的小脚本吧： 12345678910111213#!/bin/bashcurl -s https://raw.githubusercontent.com/lennylxx/ipv6-hosts/master/hosts &gt; /tmp/hosts.tmpFILTERS=( googlevideo.com)for url in $FILTERSdo sed -n "/"$url"/p" /tmp/hosts.tmp &gt; /etc/hostsdonesed -i 's/^M//g' /etc/hostscat /etc/hosts.bak &gt;&gt; /etc/hostssystemctl restart NetworkManager 由于我自己设置了一些hosts，不想被覆盖，因此把这些hosts放在了/etc/hosts.bak。 这个脚本里比较特殊的一点是^M，这个其实是\r，脚本里的^M是通过CTRL+V CTRL+M来输入的。关于这个字符的移除参考：sed Delete / Remove ^M Carriage Return (Line Feed / CRLF) on Linux or Unix - nixCraft]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《SQL入门经典》学习笔记]]></title>
    <url>%2Fp%2F7q0if%2F</url>
    <content type="text"><![CDATA[这本书总体上来讲还是比较简单的，SQL入门还是不难的。使用了三种数据库，语法有所不同，有点混乱。在看书的过程中记录了一些笔记，以便查阅吧。就是下面这本： 操作符 =相等 &lt;&gt;, != 不等 &gt;, &lt;, &gt;=, &lt;= IS NULL, IS NOT NULL BETWEEN 介于（包含端点） NOT BETWEEN IN 值在列表中, NOT IN LIKE 通配符匹配：%（&gt;0个字符）, _（1个字符）, NOT LIKE EXISTS, NOT EXISTS UNIQUE, NOT UNIQUE ALL, ANY, SOME（ANY的别名） AND, OR +, -, *, / 算术运算 汇总查询COUNT, SUM, MAX, MIN, AVG 数据排序与分组GROUP BY, ORDER BY CUBE, ROLLUP WHERE子句设定SELECT选择字段的条件；HAVING子句设定GROUP BY子句形成分组的条件。 字符函数 拼接字符串：||(Oracle), +(SQL Sever), CONCAT(MySQL) TRANSLATE 对应替换（类似于tr命令） REPLACE 替换 UPPER, LOWER SUBSTR, SUBSTRING 字符串子串 INSTR 查找，返回位置 LTRIM, RTRIM 在一侧切除字符串 DECODE 在字符串中搜索字符串，如果找到了就显示另一个字符串 IFNULL 如果是NULL就用替代值 COALESCE 依次检查，返回第一个非NULL值 LPAD, RPAD 在一侧填充 ASCII ASCII值 算术函数：ABS, ROUND, SQRT, SIGN（符号函数）, POWER, CEIL, FLOOR, EXP 与数字转换（有的可以隐式转换）：TO_NUMBER, STR, TO_CHAR 日期和时间不同的实现有所差别 MySQL：NOW, DATE_ADD, STR_TO_DATE 在查询里结合表等值结合/内部结合：利用通用字段（一般是主键）结合两个表 123SELECT TABLE1.COLUMN1, TABLE2.COLUMN2...FROM TABLE1, TABLE2WHERE TABLE1.COLUMN_NAME = TABLE2.COLUMN_NAME 将上面的=改为!=就是不等值结合、 外部结合的一般语法： 123FROM TABLE1&#123;RIGHT | LEFT | FULL&#125; [OUTER] JOIN TABLE2ON TABLE1.COLUMN_NAME = TABLE2.COLUMN_NAME 使用子查询子查询就是在另一个查询里执行的查询，用于进一步设置查询的条件。子查询不能使用ORDER BY。 关联子查询是依赖主查询里的信息的子查询，即子查询里能引用主查询里的表（类似于闭包）。 组合多个查询组合查询：有两个或多个SELECT语句 组合操作符（位于两个SELECT语句之间）： UNION 结合，不包含重复 UNION ALL 结合，包含重复 INTERSECT 返回前一个SELECT语句里与后一个SELECT语句里一样的记录 EXCEPT 返回前一个SELECT语句里有但后一个SELECT语句里没有的记录 ORDER BY可以用于组合查询，但只能用于对全部查询结果的排序；GROUP BY可以用于组合查询中每个SELECT语句，也可以用于全部查询结果；HAVING可以用于组合查询里每个SELECT语句。 123456789101112SELECT COLUMN1FROM TABLE1WHEREGROUP BYHAVING&#123;UNION | UNION ALL | EXCEPT | INTERSECT&#125;SELECT COLUMN1FROM TABLE1WHEREGROUP BYHAVINGORDER BY 高级SQL主题【存储过程】 存储过程是一组相关联的SQL语句，通常被称为函数和子程序，利用存储过程可以实现过程化编程 MySQL创建存储过程： 123456CREATE PROCEDURE PROCEDURE_NAME(ARGUMENT1 &#123;IN | OUT | IN OUT&#125; TYPE, ARGUMENT2 &#123;IN | OUT | IN OUT&#125; TYPE)ASBEGIN PROCEDURE_BODYEND; 【触发器】 MySQL创建触发器： 123456CREATE TRIGGER TRIGGER_NAME&#123;BEFORE | AFTER&#125;&#123;INSERT | UPDATE | DELETE&#125;ON TABLE_NAMEASSQL_STATEMENTS MySQL里，FOR EACH ROW可以在每条影响的记录时均执行一次触发器： 1234CREATE TRIGGER TRIGGER_NAMEON TABLE_NAMEFOR EACH ROWSQL_STATEMENTS 删除触发器：1DROP TRIGGER TRIGGER_NAME]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【实验楼】Redis基础教程——学习笔记]]></title>
    <url>%2Fp%2F7pzge%2F</url>
    <content type="text"><![CDATA[Redis数据类型字符串设置值：set key value获取值：get key没有相同key时才设置值：set key newval nx拥有相同key时才设置值：set key newval xx 增加1：incr key增加x：incrby key x 同时设置多个值：mset key1 value1 key2 value2同时获取多个值：mget key1 key2 列表PUSH: lpush 插入新元素到头部；rpush 插入新元素到尾部（一次可以push多个元素）POP: lpop 删除头部元素；rpop 删除尾部元素 查看列表所有元素：lrange key 0 -1清空列表元素/删除列表：del key hash表HMSET命令设置一个多域的hash表：hmset key k1 v1 k2 v2HGET命令获取指定的单域：hget key k1HMGET命令获取指定的多域：hmget key k1 k2HGETALL命令获取指定key的所有信息：hgetall key 可以根据需要对hash表的表项进行单独的操作，如HINCRBY：hincrby key k1 x 无序集合无序集合不包含重复元素，添加、删除、测试元素存在：O(1) 向无序集合中添加元素：sadd key x1 x2 x3查看集合元素：smembers key查看集合是否包含元素x：sismember key x 有序集合有序集合不包含重复元素，添加、删除、更新元素：O(logN)。有序集合需要元素评分来决定元素次序。 ZADD添加元素: zadd key score valueZRANGE查看元素：zrange key 0 -1ZREVRANGE逆序查看元素：zrevrange key 0 -1使用WITHSCORES参数返回评分：zrange key 0 -1 withscores Redis系统管理EXISTS 判断key是否存在DEL 删除keyTYPE 返回key元素的数据类型KEYS 返回通配符匹配的key列表RANDOMKEY 随机获得一个已经存在的keyCLEAR 清屏RENAME 改key的名字，新键如果存在将被覆盖RENAMENX 改key的名字，新建如果存在则更新失败DBSIZE 返回当前数据库的key的总数 EXPIRE 设置某个key的过期时间（秒），也可以在SET命令中设置过期时间：set key value ex secondsTTL 查询还有多长时间过期 FLUSHDB 清空当前数据库中的所有键FLUSHALL 清空所有数据库中的所有键 CONFIG GET 读取配置CONFIG SET 更改配置AUTH 使用密码认证CONFIG RESETSTAT 重置数据统计报告 INFO 查询Redis相关信息 Redis的高级应用认证方式： 登录时 redis-cli -a password 登录后 auth password 事务： 开始事务：multi 运行事务：exec 两种持久化方式： snapshotting（快照，默认方式）：将数据存放到文件 append-only file（aof）：将读写操作存放到文件中 SAVE 将数据写入磁盘]]></content>
  </entry>
  <entry>
    <title><![CDATA[深度学习CUDA配置指南]]></title>
    <url>%2Fp%2F7p7cg%2F</url>
    <content type="text"><![CDATA[查看显卡信息要使用CUDA，必须要有NVIDIA显卡，可以使用lspci命令来查看： 12345$ lspci | grep NVIDIA02:00.0 VGA compatible controller: NVIDIA Corporation Device 1b06 (rev a1)02:00.1 Audio device: NVIDIA Corporation Device 10ef (rev a1)03:00.0 VGA compatible controller: NVIDIA Corporation Device 1b06 (rev a1)03:00.1 Audio device: NVIDIA Corporation Device 10ef (rev a1 例如，上面显示显卡是NVIDIA的，1b06是deviceID，是厂商给自己某个型号的产品分配的ID。那么，如何通过deviceID来查询产品型号呢？网上有一些deviceID的数据库，例如：envytools。在此页面可查得1b06的产品型号为GeForce GTX 1080 Ti。 安装显卡驱动以Ubuntu为例，可以使用命令ubuntu-drivers list来查看合适的显卡驱动，安装较新的驱动即可： 12345678$ ubuntu-drivers listnvidia-390nvidia-384nvidia-387nvidia-396nvidia-410$ sudo apt update$ sudo apt install nvidia-410 如果输出为空，可以尝试换apt的软件源或添加ppa。另外，也可以到NVIDIA 驱动程序下载下载驱动并安装： 以Ubuntu为例，在选择操作系统时，如果有Ubuntu的选项就选Ubuntu而不是Linux，前者下载的是deb格式的安装包，后者是run格式。 对于deb格式，使用如下命令进行安装： 1$ sudo dpkg -i xxx.deb 对于run格式，需要屏蔽Ubuntu自带的开源显卡驱动nouveau，关闭X环境（不带图形界面，仅有字符界面），然后安装。由于这种安装方式较为繁琐，且容易出错，因此尽量采用前面的安装方式。详细安装方法见「安装CUDA」一节的“官方安装指南”。 安装CUDA到CUDA官方下载可以下载最新版本的cuda，也可以到CUDA Toolkit Archive | NVIDIA Developer下载各版本cuda。 选择合适的操作系统，安装类别推荐network，不推荐runfile。 然后按照Installation Instructions安装即可。 需要注意的是，最后一步 1$ sudo apt install cuda 会安装最新版本的cuda，且有新版本时可升级到最新。如果想装某个版本的cuda，可以指定版本，并且会保持该版本，除非后续又安装了其它版本。例如指定版本cuda 9.0： 1$ sudo apt install cuda-9-0 然后设置PATH和LD_LIBRARY_PATH： 12export PATH=$PATH:/usr/local/cuda/binexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH 可以写入到/etc/profile.d/cuda-env.sh，然后运行source使之生效： 1$ source /etc/profile.d/cuda-env.sh 官方安装指南可以参考： 官方安装指南 Installation Guide Linux :: CUDA Toolkit Documentation 安装CUDNN到CUDNN官网下载NVIDIA cuDNN | NVIDIA Developer最新版本cudnn，可以到cuDNN Archive | NVIDIA Developer下载各版本cudnn。下载需要登录，选择cuda所对应的版本，Runtime Library和Developer Library都安装。 以Ubuntu为例，推荐使用deb格式的安装文件。 手动安装需注意：cudnn包含cudnn的库和头文件，需要确保库位于默认位置或LD_LIBRARY_PATH，否则需要将cudnn的库所在路径加入LD_LIBRARY_PATH。 说明 除了设置LD_LIBRARY_PATH，也可以使用ldconfig来管理动态链接库的路径。 NCCL、TensorRT可以到NVIDIA Collective Communications Library (NCCL) | NVIDIA Developer下载安装NCCL。 TensorRT官方安装指南：TensorRT Installation Guide :: Deep Learning SDK Documentation 安装比较简单，在此不赘述。 说明 需要注意本地repo的概念，安装了本地repo实际上并没有安装该repo里的包，需要先进行apt update，然后仍然需要使用apt install进行安装。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[撸了个LeetCode题解仓库自动生成与发布的工具]]></title>
    <url>%2Fp%2F7odvq%2F</url>
    <content type="text"><![CDATA[前言看到有不少人在GitHub展示自己的LeetCode题解。其实我自己也在GitHub记录了自己的LeetCode题解，但是，从做题到整理，需要很多时间。本来刷题就需要时间，也够累的，还要整理，再写出来，一道题得花上好久。 最近在LeetCode上刷了上百道题目，当然，不少是Easy难度的。如果让我手动去整理，我觉得太费时间了。我一直贯彻一种理念，简单不麻烦的事容易坚持。于是，我就想着，是否能用程序来去做这些呢？ 以前在刷题的时候没注意到右侧的Notes，后来偶尔注意到了，突发灵感，这个不正好可以用来写解题思路吗？于是，我就希望有个工具能整理我刷过的题目和我的解答，还有Notes。但是，找了一圈，没发现合适的，所以，干脆就自己花了大概一天半的时间撸了一个：leetcode-publisher 说一下这个工具和别的类似的工具的不同点吧。在GitHub上看到有人做过类似的工具，但是是基于headless的浏览器做的，我觉得这种方式不够优雅。其实LeetCode的请求构造并没有很麻烦，主要是csrftoken，在cookies里有，在请求头要传x-csrftoken和referer。另外，类似的LeetCode题解仓库其实放的主要是程序源代码，这并不是我想要的。因为Markdown格式可以很方便插入代码，而且，刷题的代码并不长，放在Markdown里，和题目与笔记一起，更为合适。 当然，关于这个工具更具体的信息还是到GitHub去看吧～ jlice/leetcode-publisher: Automatically generate and publish LeetCode solution repository（LeetCode题解仓库自动生成与发布） 总结简单总结下做这个小项目的过程中遇到的一些困难与解决方案。 csrftokenCSRF是跨站请求伪造，因为server不能给其它domain设置cookies，所以可以在请求时带上一个随机token来验证是否跨域。LeetCode要求请求头要有x-csrftoken和referer。 unicode字符串在获取提交的代码时，是通过正则表达式提取网页实现的，网页里用的unicode编码。比如，换行符是\u000A，但是，通过正则表达式提取，会被视为字符串\\u000A。问题是，如何把形如\\u000A的字符串转换成对应unicode字符（\n）。一开始我是想的替换和eval，结果各种试还是不行。最终想到的方法是： 123456&gt;&gt;&gt; s = '\\u000A'&gt;&gt;&gt; s'\\u000A'&gt;&gt;&gt; s = s.encode('utf-8').decode('unicode-escape')&gt;&gt;&gt; s'\n' 其它当然，还遇到了其它的一些问题，不过相对比较好解决。 比如说，HTTP 429。HTTP 429表示一定时间内请求太多。这个容易处理，捕获HTTPError，出错时等待一段时间再试即可。 另外，用subprocess调用Shell命令cd切换目录时在下一条命令并不生效，因为每条命令其实是相对独立的！要用os.chdir来切换工作目录！ 为了让这个项目更有范，写英文README也是费了心思，毕竟英语写作太差了，最后还是借助Google翻译，唔。。。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中list的remove方法的坑]]></title>
    <url>%2Fp%2F7o05h%2F</url>
    <content type="text"><![CDATA[在做LeetCode上的一道非常简单的题目find-all-numbers-disappeared-in-an-array时，竟然做错了。经过Debug发现，Python在移除list中的True把1也移除了。为了说明这个问题，下面是示例代码： 1234567&gt;&gt;&gt; a = [1, 2, True]&gt;&gt;&gt; a.remove(True)&gt;&gt;&gt; a[2, True]&gt;&gt;&gt; a.remove(True)&gt;&gt;&gt; a[2] 可以发现，移除True时，把1也给移除了，但是2没有被移除。 1234&gt;&gt;&gt; a = [True]&gt;&gt;&gt; a.remove(1)&gt;&gt;&gt; a[] 而当list里的元素是True，移除1时把True也给移除了。 因此，可以看出，True和1是等同的。做类似的实验，False和0是等同的。甚至True和False也可以进行算术运算： 12345678&gt;&gt;&gt; 1 == TrueTrue&gt;&gt;&gt; 0 == FalseTrue&gt;&gt;&gt; True + 12&gt;&gt;&gt; False + 11]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记因内核版本错误导致U盘不能识别的问题解决]]></title>
    <url>%2Fp%2F7l9mo%2F</url>
    <content type="text"><![CDATA[U盘插上电脑，发现没有自动挂载。然后运行 1$ sudo fdisk -l 一看，发现并没有U盘所对应的设备，也就是U盘不能识别了！以前从没在Linux上遇到这种问题，通过查资料得知，要识别U盘，需要装载usb-storage模块。 于是，运行 1$ lsmod | grep usb 发现确实没有usb-storage模块。 为了判断U盘是否物理损坏导致系统无法“感知”U盘的存在，运行命令 1$ sudo udevadm monitor --udev 发现U盘插拔时有反应。 然后运行： 12$ sudo modprobe usb-storagemodprobe: FATAL: Module usb-storage not found in directory /lib/modules/4.14.48-2-MANJARO 尝试装载usb-storage模块，结果报错。 查看/lib/modules/目录： 123$ ls /lib/modules 4.14.40-rt30-MANJARO extramodules-4.14-MANJARO4.14.52-1-MANJARO extramodules-4.14-rt-MANJARO 发现并没有4.14.48-2-MANJARO。在Manjaro设置管理器里查看内核： 发现当前内核版本为4.14.52-1。但是，运行 1$ uname -r 却显示内核版本为4.14.48-2-MANJARO。这也难怪modprobe会到/lib/modules/4.14.48-2-MANJARO目录下去找usb-storage模块。 通过查询modprobe的manpage，发现可以指定版本。运行 1$ sudo modprobe --set-version=4.14.52-1-MANJARO usb-storage U盘终于自动挂载了！ 为了启动时使用4.14.52-1版本的内核，运行 1$ sudo update-grub 来更新grub，重启后再运行 1$ uname -r 显示内核版本为4.14.52-1-MANJARO，U盘也能自动挂载，运行 1$ lsmod | grep usb 也有usb-storage模块，问题解决。 【后记】更新内核后最好重启下]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PPM、PGM、PBM图像格式剖析]]></title>
    <url>%2Fp%2F7l2u9%2F</url>
    <content type="text"><![CDATA[今天突然需要用到PPM这个图像文件格式，之前没见过，在此记录一下。 PPM、PGM、PBM这三个图像文件格式很少见，其实也不难，分别用于彩色图像、灰度图像、二值图像。这里以PPM格式为例。 PPM格式有两种类型：字节码和ASCII。前者是二进制文件，后者是纯文本文件。 使用convert命令可以将图像转为PPM格式： 1234# 字节码$ convert xxx.jpg xxx.ppm# ASCII$ convert xxx.jpg -compress none xxx.ppm ASCII类型的PPM文件示例： 1234P31305 1305255229 232 237 228 231 236 ... 第1行是P3，第2行是图像大小，第3行是最大值，一般是255。从第4行起就是每个像素的颜色值了，像素顺序一般是从左到右、从上到下，通道顺序一般是RGB。 字节码类型的PPM文件示例： 150 36 0A 31 33 30 35 20 31 33 30 35 0A 32 35 35 0A E5 E8 ED E4 E7 EC ... 最开始的50 36对应ASCII为P6，31 33 30 35对应ASCII为1305。32 35 35对应ASCII为255。后面的像素值以十六进制表示： 123456789$ bc -qobase=10ibase=16E5229E8232ED237 Python的Pillow库可以读取、存储字节码类型的PPM格式： 123456789from PIL import Image# 存储PPM格式im = Image.open('xxx.jpg')im.save('xxx.ppm')# 读取PPM格式im = Image.open('xxx.ppm')im.show() PGM头部用P2和P5分别表示ASCII类型和字节码类型；PBM头部用P1和P4分别表示ASCII类型和字节码类型，但没有像PPM第3行的最大值，ASCII类型的像素值都是0或1。]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用油猴脚本显示扇贝网真实打卡日记]]></title>
    <url>%2Fp%2F7kmxm%2F</url>
    <content type="text"><![CDATA[前一段时间发现扇贝网页版显示的打卡日记和手机上看到的不一致，感觉应该是网页版开发滞后的原因。这种不一致给查卡带来了诸多不便，于是就设法解决该问题。 起初我想到的方案是做一个静态页面放到对象存储上，然后对象存储开启静态服务，静态页面通过Ajax请求手机版的RESTful接口获取数据，然后生成打卡日记。不过，通过反复试验发现这种方法行不通。 123$.get(url, function(data)&#123; // do something&#125;); 直接使用Ajax请求会报错： No ‘Access-Control-Allow-Origin’ header is present on the requested resource. 这是因为服务器不允许跨站。 然后接触到了用JSONP来进行跨站请求。因为js脚本可以跨站，像静态博客的评论功能就是用的跨站js脚本，JSONP的思路是在请求的地址上携带一个callback参数，服务端以这个callback参数作为函数名包裹JSON数据，然后在返回数据时调用这个函数，就把JSON数据传过来了。 1234567$.ajax(&#123; url: url, dataType: 'jsonp', success: function(json)&#123; // do something &#125;&#125;); 但是，使用JSONP的前提同样是需要服务器端的配合。假如服务器端不适配JSONP，也就是不返回包裹JSON数据的函数，而是依旧返回JSON，那么JSON数据就会被视为javascript脚本运行，会报错： Uncaught SyntaxError: Unexpected token : 然后想到iframe也可以跨站，于是试试iframe，结果发现依然是想多了： Refused to display ‘*‘ in a frame because it set ‘X-Frame-Options’ to ‘deny’. 也就是iframe也是需要服务器端配合。假如服务器端不允许iframe，那么iframe便不能跨站。 跨站请求其实也比较危险，例如XSS、CSRF。于是，我决定不通过跨站请求，而是利用油猴脚本来实现我的需求，顺便补充了点jQuery。 12345678910111213141516171819202122232425262728293031323334353637383940// ==UserScript==// @name 显示真实打卡日记// @namespace https://www.shanbay.com/// @version 0.1// @description 显示时区、真实打卡日记、打卡时间// @author 文剑木然// @match https://www.shanbay.com/checkin/user/*// @grant MIT// @require https://static.baydn.com/static/scripts/jquery-1.7.2.min.js// ==/UserScript==$(function()&#123; var url = window.location.href .replace('www.shanbay.com', 'www.shanbay.com/api/v1') .replace('?page', '?ipp=10&amp;page'); $.get(url, function(json)&#123; // 显示时区 var timezone = json.data[0].user.timezone; if(json.data.length &gt; 0 &amp;&amp; timezone !== 'Asia/Shanghai')&#123; $('h2').html($('h2').html() + '（' + timezone +'）'); &#125; // 修改打卡日记 for(var i=0; i&lt;10; i++)&#123; var idata = json.data[i]; var icheckin = $('#checkin').children().eq(i); var number = icheckin.find('span.number'); number.html(' ' + idata.num_checkin_days); var note = icheckin.find('div.note'); if(json.data[i].note_length === 0)&#123; note.html(idata.info); &#125;else&#123; note.html(idata.info + ' , ' + idata.note); &#125; var date = icheckin.find('div.span4'); date.html('&lt;strong&gt;' + idata.checkin_date + '&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;(' + idata.checkin_time.replace('T', '&amp;nbsp;&amp;nbsp;') + ')'); &#125; &#125;);&#125;); jQuery中，children()指直接子元素，.find()能递归查找子元素，.eq(i)为第i个元素。用jQuery来修改DOM还是十分简便的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[向量微积分基础]]></title>
    <url>%2Fp%2F7kemt%2F</url>
    <content type="text"><![CDATA[机器学习里经常需要用到向量微积分。向量微积分其实并不难，但大学数学一般不提，导致在看机器学习的一些推导时常常感觉疑惑。 机器学习里经常用到标量和向量、向量和向量的求导，其实只是把向量对应位置的元素进行求导。但是，这些元素的组织方式有两种，分别是分子布局和分母布局，二者并无本质上的差别，只是结果相差个转置。这两种布局都存在，初学者常常混淆。 例如求\frac {\partial \mathbf{y}} {\partial x}，其中\mathbf{y}是n维列向量，x是标量。这个求导就是把\mathbf{y}里每个元素分别对x求导，但求导后是得到列向量还是行向量呢？ 对于分子布局： \frac {\partial \mathbf{y}} {\partial x} = \begin{bmatrix} \frac {\partial y_1} {\partial x} \\ \frac {\partial y_2} {\partial x} \\ \vdots \\ \frac {\partial y_n} {\partial x} \\ \end{bmatrix}对于分母布局： \frac {\partial \mathbf{y}} {\partial x} = \begin{bmatrix} \frac {\partial y_1} {\partial x} & \frac {\partial y_2} {\partial x} & \dots & \frac {\partial y_n} {\partial x} \\ \end{bmatrix}两种布局容易混淆，建议选择自己习惯的布局即可。这里我们选择分子布局进行后面的说明。 符号约定：小写粗体：值为向量；大写粗体：值为矩阵；小写斜体：值为标量。以a、b、c、d表示和x无关的函数，u=u(x)，v=v(x)，f、g、h是函数。 \frac{\partial y}{\partial \mathbf{x}} = \begin{bmatrix} \frac{\partial y}{\partial x_1} & \frac{\partial y}{\partial x_2} & \dots & \frac{\partial y}{\partial x_n} \\ \end{bmatrix} \frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \begin{bmatrix} \frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n}\\ \frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} & \cdots & \frac{\partial y_2}{\partial x_n}\\ \vdots & \vdots & \ddots & \vdots\\ \frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_2} & \cdots & \frac{\partial y_m}{\partial x_n}\\ \end{bmatrix}这个矩阵又叫雅可比（Jacobi）矩阵。 \frac{\partial y}{\partial \mathbf{X}} = \begin{bmatrix} \frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{21}} & \cdots & \frac{\partial y}{\partial x_{p1}}\\ \frac{\partial y}{\partial x_{12}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{p2}}\\ \vdots & \vdots & \ddots & \vdots\\ \frac{\partial y}{\partial x_{1q}} & \frac{\partial y}{\partial x_{2q}} & \cdots & \frac{\partial y}{\partial x_{pq}}\\ \end{bmatrix}虽然看着挺复杂，但不难看出：分子布局的特点是，分子的编号排列和分子相同，分母的编号排列和分母的转置相同。 一些求导公式比较常用，在此列举一下： \frac {\partial {\mathbf{Ax}}} {\partial \mathbf{x}} = \mathbf{A} \frac {\partial \mathbf{x}^\top \mathbf{X}} {\partial \mathbf{x}} = \mathbf{A}^\top \frac {\partial \mathbf{x}^\top \mathbf{x}} {\partial \mathbf{x}} = 2 \mathbf{x}^\top \frac {\partial \mathbf{x}^\top \mathbf{A} \mathbf{x}} {\partial \mathbf{x}} = \mathbf{x}^\top(\mathbf{A} + \mathbf{A}^\top)若$\mathbf{A}$为对称阵，则对于上式： \begin{split} \frac {\partial \mathbf{x}^\top \mathbf{A} \mathbf{x}} {\partial \mathbf{x}} &= \mathbf{x}^\top(\mathbf{A} + \mathbf{A}^\top) \\ &= 2 \mathbf{x}^\top\mathbf{A} \end{split}和、积的导数： \frac {\partial (\mathbf{u} + \mathbf{v})} {\partial \mathbf{x}} = \frac {\partial \mathbf{u}} {\partial \mathbf{x}} + \frac {\partial \mathbf{v}} {\partial \mathbf{x}} {\frac {\partial ({\mathbf {u}}\cdot {\mathbf {v}})}{\partial {\mathbf {x}}}}={\frac {\partial {\mathbf {u}}^{\top }{\mathbf {v}}}{\partial {\mathbf {x}}}}= {\mathbf {u}}^{\top }{\frac {\partial {\mathbf {v}}}{\partial {\mathbf {x}}}}+{\mathbf {v}}^{\top }{\frac {\partial {\mathbf {u}}}{\partial {\mathbf {x}}}}链式求导： \frac{\partial \mathbf{f(u)}}{\partial \mathbf{x}} = \frac{\partial \mathbf{f(u)}}{\partial \mathbf{u}} \frac{\partial \mathbf{u}}{\partial \mathbf{x}}更多详细内容可以参考：Matrix calculus - Wikipedia]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性最小二乘法推导]]></title>
    <url>%2Fp%2F7ka8s%2F</url>
    <content type="text"><![CDATA[代数形式最小二乘法在中学时讲过。有一些散点有线性的趋势，用一个一次函数去拟合，使得差距最小化。 假设数据点为 $(x_1, y_1), (x_2, y_2),\dots,(x_m, y_m)$ ，使用如下一次函数去拟合： y = w_1 x + w_0对于 $x_i$ ，采用上述函数计算出的结果记为 $\hat{y_i}$ ，即： \hat{y_i} = w_1 x_i+w_0定义差距为： \sum_{i=1}^m (y_i - \hat{y_i})^2现需要最小化这个差距。显然，上式为关于 $w_0$ 和 $w_1$ 的函数（损失函数）。为了方便，将 $\sum\limits_{i=1}^m$ 简记为 $\sum$ ，记： \begin{split} f(w_0, w_1) &= \sum (y_i - \hat{y_i})^2 \\ &= \sum (y_i - (w_1 x_i + w_0))^2 \\ &= \sum (y_i^2 - 2y_ix_iw_1 - 2y_iw_0 + x_i^2w_1^2 + w_0^2 + 2x_iw_0w_1) \\ \end{split}分别对 $w_0, w_1$ 求偏导： \begin{split} \frac {\partial f} {\partial w_0} &= \sum (-2y_i + 2w_0 + 2x_iw_1) \\ &= -2 \sum {y_i} + 2mw_0 + 2w_1 \sum {x_i} \\ \frac {\partial f} {\partial w_1} &= \sum (-2x_iy_i + 2x_i^2w_1 + 2w_0x_i) \\ &= -2\sum{x_iy_i} + 2w_1\sum {x_i^2} + 2w_0\sum {x_i} \\ \end{split}令： \begin{split} \frac {\partial f} {\partial w_0} &= 0 \\ \frac {\partial f} {\partial w_1} &= 0 \\ \end{split}得： \begin{split} mw_0 + w_1\sum{x_i} &= \sum{y_i} \\ w_1\sum{x_i^2} + w_0\sum{x_i} &= \sum{x_i}{y_i} \\ \end{split}联立上面两式可得： \begin{split} w_0 &= \frac {\sum{x_i}\sum{x_i y_i} - \sum{y_i}\sum{x_i^2}} {(\sum{x_i})^2 - m\sum{x_i^2}} \\ w_1 &= \frac {\sum{x_i}\sum{y_i} - m\sum{x_i y_i}} {(\sum{x_i})^2 - m\sum{x_i^2}} \\ \end{split}注意， $\sum{x_i^2} \ne (\sum{x_i})^2$ ，计算时要细心。 矩阵形式记 $\mathbf{X}$ 为 $m\times n$ 的矩阵，表示有 $m$ 个样本点，特征维数为 $n$ 维； $\mathbf{y}$ 为 $m$ 维列向量，表示这 $m$ 个样本点的实际值； $\mathbf{\hat{y}}$ 为 $m$ 维列向量，表示这 $m$ 个样本点的估计值； $\mathbf{w}$ 为 $n$ 维列向量，且： \mathbf{\hat{y}} = \mathbf{X}\mathbf{w}则： \mathbf{y} - \mathbf{\hat{y}} = \mathbf{y} - \mathbf{X}\mathbf{w}上式的结果是一个列向量，而我们需要的是其平方和。根据矩阵乘法的定义，损失函数为： f(\mathbf{w}) = (\mathbf{y} - \mathbf{X}\mathbf{w})^{\rm T}(\mathbf{y} - \mathbf{X}\mathbf{w})现要求 $\frac {\partial f} {\partial \mathbf{w}}$ ，可 $\mathbf{w}$ 是个向量呀，这个该怎么求呢？ 预备知识【实数值函数对向量求导】 \frac {\partial f} {\partial \mathbf{x}} = \begin{bmatrix} \frac{\partial f}{x_1} & \frac{\partial f}{x_2} & \dots & \frac{\partial f}{x_n} \\ \end{bmatrix}其中， $\mathbf{x}= \left[x_1, x_2, \dots, x_n\right]^{\rm T}$ 为 $n$ 维列向量， $f$ 是 $\mathbf{x}$ 上 $\Re^n \to \Re$ 的函数（也就是， $f$ 的输入是 $n$ 维列向量，输出是实数） 【向量值函数对向量求导】 \frac {\partial \mathbf{y}} {\partial \mathbf{x}} = \begin{bmatrix} \frac{\partial{y_1}}{\partial x_1} & \frac{\partial{y_1}}{\partial x_2} & \dots & \frac{\partial{y_1}}{\partial x_n} \\ \frac{\partial{y_2}}{\partial x_1} & \frac{\partial{y_2}}{\partial x_2} & \dots & \frac{\partial{y_2}}{\partial x_n} \\ \vdots & \vdots & \ddots & \vdots \\ \frac{\partial{y_m}}{\partial x_1} & \frac{\partial{y_m}}{\partial x_2} & \dots & \frac{\partial{y_m}}{\partial x_n} \\ \end{bmatrix}即： (\frac {\partial \mathbf{y}} {\partial \mathbf{x}})_{ij} = \frac{\partial{y_i}}{\partial x_j}其中， $\mathbf{x}= \left[x_1, x_2, \dots, x_n\right]^{\rm T}$ 为 $n$ 维列向量， $\mathbf{y}$ 是定义在 $\mathbf{x}$ 上 $\Re^n \to \Re^m$ 的函数（也就是， $\mathbf{y}$ 的输入是 $n$ 维列向量，输出是 $m$ 维列向量），上面的矩阵称为雅可比（Jacobi）矩阵。 【链式求导】 设 $\mathbf{x}$ 为列向量，复合函数 $\mathbf{h(\mathbf{x}) = \mathbf{f(\mathbf{g(\mathbf{x})})}}$ ，其中向量值函数（也就是函数的值域是向量）$\mathbf{f(\mathbf{g})}$ 和 $\mathbf{g(\mathbf{x})}$ 均可微，则： \mathbf{h}^\prime(\mathbf{x}) = \mathbf{f}^\prime(\mathbf{g(\mathbf{x})})\mathbf{g}^\prime(\mathbf{x})和代数形式的链式求导类似。 计算过程记 $\mathbf{u(\mathbf{w})} = \mathbf{y} - \mathbf{X}\mathbf{w}$ ，则： \begin{split} f &= \mathbf{u}^{\rm T} \mathbf{u} \\ &= \sum\nolimits_i {u_i^2} \\ \end{split} \begin{split} \frac {\partial f} {\partial \mathbf{u}} &= \begin{bmatrix} \frac {\partial {\sum\nolimits_i {u_i^2}}} {\partial {u_1}} & \frac {\partial {\sum\nolimits_i {u_i^2}}} {\partial {u_2}} & \dots & \frac {\partial {\sum\nolimits_i {u_i^2}}} {\partial {u_i}} \\ \end{bmatrix} \\ &= \begin{bmatrix} 2u_1 & 2u_2 & \dots & 2u_i \end{bmatrix} \\ &= 2 \begin{bmatrix} u_1 & u_2 & \dots & u_i \end{bmatrix} = 2 \mathbf{u}^{\rm T}\\ \end{split} \begin{split} \mathbf{u} &= \mathbf{y} - \mathbf{X}\mathbf{w} \\ &= \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_m \\ \end{bmatrix} - \begin{bmatrix} x_{11} & x_{12} & \dots & x_{1n} \\ x_{21} & x_{22} & \dots & x_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & \dots & x_{mn} \\ \end{bmatrix} \begin{bmatrix} w_1 \\ w_2 \\ \vdots \\ w_n \\ \end{bmatrix} \\ &= \begin{bmatrix} y_1 - \sum {x_{1i}w_i} \\ y_2 - \sum {x_{2i}w_i} \\ \vdots \\ y_m - \sum {x_{mi}w_i} \\ \end{bmatrix} \\ \end{split} \begin{split} (\frac{\partial {\mathbf{u}}}{\partial {\mathbf{w}}})_{ij} &= \frac{\partial u_i}{\partial w_j} \\ &= \frac{\partial (y_i - (x_{i1}w_1 + x_{i2}w_2 + \dots + x_{in}w_n))}{\partial w_j} \\ &= -x_{ij} \end{split} \frac{\partial \mathbf{u}}{\partial \mathbf{w}} = - \mathbf{X}使用链式求导： \begin{split} \frac {\partial f} {\partial {\mathbf{w}}} &= \frac {\partial f} {\partial \mathbf{u}} \frac {\partial \mathbf{u}} {\partial \mathbf{w}} \\ &= 2 \mathbf{u}^{\rm T} (- \mathbf{X}) \\ &= -2(\mathbf{y} - \mathbf{X}\mathbf{w})^{\rm T}\mathbf{X} \\ &= -2 (\mathbf{y}^{\rm T} - (\mathbf{X}\mathbf{w})^{\rm T})\mathbf{X} \\ &= -2 (\mathbf{y}^{\rm T} - \mathbf{w}^{\rm T}\mathbf{X}^{\rm T}) \mathbf{X} \\ &= -2 (\mathbf{y}^{\rm T}\mathbf{X} - \mathbf{w}^{\rm T}\mathbf{X}^{\rm T}\mathbf{X}) \end{split}令： \frac{\partial f}{\partial \mathbf{w}} = \mathbf{0}得： \mathbf{w}^{\rm T}\mathbf{X}^{\rm T}\mathbf{X} = \mathbf{y}^{\rm T}\mathbf{X}若 $\mathbf{X}^{\rm T}\mathbf{X}$ 可逆，则两边同时右乘 $(\mathbf{X}^{\rm T}\mathbf{X})^{-1}$ ，得： \mathbf{w}^{\rm T} = \mathbf{y}^{\rm T}\mathbf{X}(\mathbf{X}^{\rm T}\mathbf{X})^{-1}两边同时转置： \begin{split} \mathbf{w} &= (\mathbf{y}^{\rm T}\mathbf{X}(\mathbf{X}^{\rm T}\mathbf{X})^{-1})^{\rm T} \\ &= ((\mathbf{X}^{\rm T}\mathbf{X})^{-1})^{\rm T}\mathbf{X}^{\rm T}(\mathbf{y}^{\rm T})^{\rm T} \\ &= ((\mathbf{X}^{\rm T}\mathbf{X})^{\rm T})^{-1}\mathbf{X}^{\rm T}\mathbf{y} \\ &= (\mathbf{X}^{\rm T}(\mathbf{X}^{\rm T})^{\rm T})^{-1}\mathbf{X}^{\rm T}\mathbf{y} \\ &= (\mathbf{X}^{\rm T}\mathbf{X})^{-1}\mathbf{X}^{\rm T}\mathbf{y} \\ \end{split}]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Dia在Linux上的输入法问题]]></title>
    <url>%2Fp%2F7k91v%2F</url>
    <content type="text"><![CDATA[Dia是一个比较小巧的画图软件，支持Windows、Mac和Linux，功能类似于Visio。个人觉得Dia还挺好用的，不过，有个比较烦的地方就是用不了中文输入法。在Linux上，输入法比较折腾。 按网上的说法改/usr/bin/dia不行，用dia-normal提示没这个命令。不过，我自己发现了解决方案。 探索历程运行dia --help，可以看到有个--classic选项。尝试使用这个选项运行，Dia就能输入中文了，只是工具箱面板分离了。 虽然这样算是解决了输入法问题，但是，窗口太小了，还不能记住窗口大小，所以每次都要拖一下窗口大小，用起来挺不方便、不够优雅。 在Windows平台上，Dia也是默认用不了中文输入法，但是菜单栏有个输入法菜单，选择输入法为”简单“即可。在Ubuntu上好像菜单栏也有输入法菜单，但是Deepin（也就是我在用的Linux发行版）上，Dia菜单栏上没有输入法菜单。 今天偶然发现，打开Dia后，在要输入文字时，右键就有输入法的菜单，选择”X输入法“就能用中文输入法了，而且也不会面板分离。 可是，每次要输入中文时都右键选择一下还是不够优雅。有彻底终结Dia输入法问题的方案吗？ 既然Dia能选择输入法，那么其环境变量应该有输入法相关的。于是，运行dia &amp;会后台启动Dia，并且显示其PID，然后cat /proc/&lt;PID&gt;/environ就能显示其环境变量了。Dia是GTK应用程序，”X输入法“英文是”X input method”，简写”xim”，在im-config里也有”xim”。而在Dia的环境变量里有GTK_IM_MODULE=fcitx（我用的是搜狗输入法），Dia应该是通过这个环境变量来选择输入法的。尝试运行GTK_IM_MODULE=xim dia发现就能用中文输入法了！ 终极方案所以，解决方案就是设置Dia的环境变量，使得GTK_IM_MODULE=xim就行了。具体来说，修改/usr/share/applications/dia.desktop: 1Exec=env GTK_IM_MODULE=xim dia %F 至于从终端启动Dia，可以写条alias： 1alias dia="env GTK_IM_MODULE=xim dia"]]></content>
  </entry>
  <entry>
    <title><![CDATA[重写了图床神器，支持七牛云和腾讯云]]></title>
    <url>%2Fp%2F7k90b%2F</url>
    <content type="text"><![CDATA[前言用Python重写了图床神器，支持七牛云和腾讯云。用Python写起来感觉顺滑多了～贴一下效果： 项目地址：lpic: 终端图床神器 为什么要想着重写图床神器呢？ 因为，突然发现七牛云的外链不是HTTPS的，然后谷歌浏览器地址栏就没有小绿锁了，标记网站为不安全。而腾讯云的外链是HTTPS的，而且，腾讯云免费额度更多（虽然七牛云10G也足够）。想了想，还是搬到腾讯云吧。貌似谷歌会在以后版本的谷歌浏览器将HTTP用红色警告标记为不安全，所以还是早早上HTTPS比较好。 用Python重写其实难度不大，就调用调用官方SDK就行了。不过，在此过程中还是有些收获的。 总结压缩图片既然是用Python重写，通过调用命令行的方式用convert命令压缩图片就显得不够优雅了。可以用Pillow来处理： 1234from PIL import Imagewith Image.open(file) as im: im.save(new_file, format='JPEG', optimize=True) optimize=True 表示自动优化，使用JPEG压缩效果很不错。 读取YAMLyaml格式作为配置文件貌似挺火的，好像有不少软件的配置文件用的yaml。不过，我觉得yaml有点坑的地方在于，:后面要有空格，否则会解析失败。 Python可以用现成的PyYAML来读取YAML： 1234import yamlwith open(yml_file) as fp: conf = yaml.load(fp) 会解析为dict。 这里说一个小插曲，我习惯使用dict的.get(key, default)方法来设置默认值，不过在读取yaml后我用这种方式设置默认值发现没效果。后来才发现是我思维定势了，如果key存在，即使对应的值是None，也不能用这种方式设置默认值，因为key存在，而这个方法是给不存在的key设置默认值的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[撸了个七牛云图床神器]]></title>
    <url>%2Fp%2F7k6v8%2F</url>
    <content type="text"><![CDATA[图床神器，也就是在Markdown写作时方便上传图片到云上并获取外链。Mac上有图床神器iPic，貌似挺不错的，不过只支持Mac。其实，图床神器的功能并不复杂，流程大致如下： 基本上用Shell脚本就能搞定。 项目地址：lpic：Linux下的七牛云图床神器 与七牛云交互的部分直接调用官方提供的开发者工具：qrsctl，使得开发方便了许多。不过，由于对Bash编程不够熟练，在写这个小工具时还是遇到了一些问题。由于时间比较仓促，写得比较简单，不够awesome，不够robust，但够用即可～简单记录一下。 提取文件后缀：${file##*.} ##表示删除左侧最长的匹配（贪婪），#表示删除左侧最短匹配（非贪婪） %%表示删除右侧最长的匹配（贪婪），%表示删除右侧最短匹配（非贪婪） 依稀记得在鸟哥Linux私房菜里看过，不用的话有点难记。 还有更实用的是替换，比如说将$var里的xyz字符替换为abc可以用${var//xyz/abc}。其中的//表示全部替换，如果换成/就只替换第一个。这里容易和sed或vim里的替换搞混淆，写成${var//xyz/abc/}了，这样就替换成abc/了。 Bash里的函数虽说可以有返回值，也就是可以return，但只能return 0~255之间的整数，如果return -1实际是return 255，return 256实际是return 0。这一点和一般的编程语言不一样，所以，Bash函数基本就返回状态码，尽量不要用于返回数据。 Bash给变量赋值时，变量名前不需要$，只是取出它的值时需要$，这一点和PHP还是不一样的。 在用read的时候需要注意，-p参数是显示提示，但在提示内容里使用变量时还是需要留心点的。比如： 12345$ var="你 好"$ read -p "x""$var""y" ansx你 好y$ read -p "x"$var"y" ansbash: read: `好y': 不是有效的标识符 注意到上面两种写法的不同了吗？如果提示里有空格，后面的部分会被视为接收输入的变量。另外，zsh的read没有-p。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用TravisCI自动构建]]></title>
    <url>%2Fp%2F7k566%2F</url>
    <content type="text"><![CDATA[前言最近发现了个很好用的东西：TravisCI，能自动构建项目。其实，持续集成我早就有所了解，不过没怎么操作过。以前也知道TravisCI，但没有相关需求，所以就没怎么接触。这几天在找一个适合做笔记的静态网站程序，发现了MkDocs挺不错的，也看了一些静态博客程序，比如纸小墨。不过，感觉方便的不容易定制外观，因为考虑到Hexo还是用的人比较多，且我对Hexo已经有所了解，就懒得去折腾新的静态博客了。但是，在看纸小墨时有了重大发现。 在看纸小墨时，找到了使用TravisCI自动构建博客并部署，这样，用户只需要写博客，然后Push就行了，TravisCI会自动完成静态博客的构建与部署，只需要一份TravisCI配置（.travis.yml）就行了！ 想想在写代码时，提交后自动编译、运行测试，不需要手动编译测试，真的很方便。我以为这样的服务应该是收费的，就很长时间里没有去了解。最近了解一下，才发现解决了我多年来的痛点。难怪很多项目的README里会显示编译状态，原来如此。。。 TravisCI和GitHub结合的比较好，另外还有其它的持续集成工具，如Jenkins。 配置TravisCI的配置也不难，采用的是YAML格式，文件名是.travis.yml，放在项目的根目录。每次Push后会触发TravisCI的启动运行。 以下是构建MkDocs的配置： 12345678910111213141516171819language: pythonpython: - "3.5"install: - pip install mkdocs - pip install python-markdown-mathscript: - mkdocs build --clean - mkdocs buildafter_success: | if [ -n "$REPO_TOKEN" ]; then cd "$TRAVIS_BUILD_DIR" cd site git init git add . git -c user.name=$GITHUB_NAME -c user.email=$GITHUB_EMAIL commit -m "Auto Deployment" git push -f -q https://$GITHUB_NAME:$REPO_TOKEN@$REPO master:gh-pages cd "$TRAVIS_BUILD_DIR" fi GITHUB_NAME、GITHUB_EMAIL、REPO_TOKEN和REPO都是配置的环境变量，在TravisCI的项目设置里可以进行配置： 其中，REPO_TOKEN可以在GitHub Token管理生成，需要repo权限，这样TravisCI才能push代码。 可以看到，其实就是配置了一些脚本，注意命令别写错了，特别是git push。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python进行doctest]]></title>
    <url>%2Fp%2F7jai9%2F</url>
    <content type="text"><![CDATA[doctest简介在doc注释部分使用形如Python交互式命令行的代码，可以进行doctest。 123456def add(a, b): """ &gt;&gt;&gt; add(1, 2) 3 """ return a + b 运行doctest1、PyCharm设置： 选择Run&gt;Edit Configurations，新建一个doctest配置，然后运行即可。 2、命令行运行： 1$ python -m doctest -v hello.py -v选项会显示详细信息。 3、使用doctest模块： 12import doctestdoctest.testmod(verbose=True)]]></content>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow之MNIST入门]]></title>
    <url>%2Fp%2F7hqyt%2F</url>
    <content type="text"><![CDATA[MNIST手写数字识别是机器学习中非常经典的问题，相当于编程语言界的“Hello World“。关于神经网络解决MNIST手写数字识别问题，可以参考这个视频：深度学习之神经网络的结构 Part 1 ver 2.0 视频中使用的是多层神经网络，为了简化问题，这里我们使用单层的网络结构。 参考之前的MNIST数据集解析，先对MNIST数据集进行解析： 1234567891011121314151617181920212223242526272829303132import gzipimport structimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tfdef load_images(image_gz): with gzip.open(image_gz) as f: buf = f.read() num = int(struct.unpack_from('&gt;i', buf, 4)[0]) return (np.array(struct.unpack_from('B'*num*28*28, buf, 16) ).reshape(num, 784)/255).astype(np.float32)def load_labels(label_gz): with gzip.open(label_gz) as f: buf = f.read() num = int(struct.unpack_from('&gt;i', buf, 4)[0]) idx = 8 tmp = [] for i in range(num): label = int(struct.unpack_from('B', buf, idx)[0]) idx += 1 # one-hot encoding ohl = np.zeros(10, dtype=np.float32) ohl[label] = 1.0 tmp.append(ohl) return np.array(tmp)train_images = load_images('train-images-idx3-ubyte.gz')train_labels = load_labels('train-labels-idx1-ubyte.gz')test_images = load_images('t10k-images-idx3-ubyte.gz')test_labels = load_labels('t10k-labels-idx1-ubyte.gz') 在读取图片时，一次性读取二进制数据，这样可以大大提升效率。之后，为了使用的方便，将它变形为num*784大小，由于图片都是28*28大小，所以单张图片的像素数就是784。另外，还将像素值进行了归一化，因为，如果输入层的值很大，在反向传播时传递到输入层的梯度就会很大，如果梯度非常大，学习率就必须非常小，否则就会跳过局部最小（直接表现就是代价函数的值为nan）。因此，如果用梯度下降来训练模型一般都要在数据预处理步骤进行数据归一化。 对于离散的特征一般按照one-hot编码，该离散特征有多少取值，就用多少维度来表示该特征。在回归、分类、聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，使用one-hot编码，特征之间的距离更为合理。 基于树的方法不需要特征归一化，基于参数或距离的模型要进行特征归一化。 12345678X = tf.placeholder(tf.float32, (None, 784))Y = tf.placeholder(tf.float32, (None, 10))W = tf.Variable(tf.truncated_normal((784, 10), stddev=0.01))b = tf.Variable(tf.zeros((10,)))y = tf.nn.softmax(tf.matmul(X, W) + b)cost = -tf.reduce_sum(Y*tf.log(tf.clip_by_value(y, 1e-10, 1.0))) Softmax函数一般用于多分类问题，可以对预测的标签进行归一化。计算公式为： S_i = \frac {e^{x_i}} {\sum e^{x}}下面举例说明计算过程： 1234567891011a = tf.constant(np.array([ [6., 1., 0.], [0., 4., 2.]]))b = tf.nn.softmax(a)with tf.Session() as sess: print(sess.run(b))# Output:[[ 0.99086747 0.00667641 0.00245611] [ 0.01587624 0.86681333 0.11731043]] 使用Linux自带的计算器bc进行手动计算的过程（其中e(x)表示exp(x)）： 12345678910111213$ bc -lqe(6)/(e(6)+e(1)+e(0)).99086747258217259526e(1)/(e(6)+e(1)+e(0)).00667641251337645118e(0)/(e(6)+e(1)+e(0)).00245611490445095354e(0)/(e(0)+e(4)+e(2)).01587623997646676632e(4)/(e(0)+e(4)+e(2)).86681333219733487114e(2)/(e(0)+e(4)+e(2)).11731042782619836253 使用的代价函数为： C = -\sum [Y\log(y)]由于y可能有元素值为0，造成log(y)无意义，从而使得代价函数的值为nan，所以这里使用tf.clip_by_value对其值进行修剪，设定值的下限和上限。 为了说明cost的计算，列举一些例子： 12345678910111213a = tf.constant(np.array([ [1., 0., 0., 0., 0.], [0., 0., 1., 0., 0.]]))b = tf.constant(np.array([ [0.8, 0.1, 0.1, 0., 0.], [0., 0., 0.9, 0., 0.1]]))c = -tf.reduce_sum(a*tf.log(tf.clip_by_value(b, 1e-10, 1.)))with tf.Session() as sess: print(sess.run(c))# Output:0.328504066972 这个的计算式子是： 12345-1*( 1.0*log(0.8)+0.0*log(0.1)+0.0*log(0.1)+0.0*log(0.0)+0.0*log(0.0) + 0.0*log(0.0)+0.0*log(0.0)+1.0*log(0.9)+0.0*log(0.0)+0.0*log(0.1))=-1*(log(0.8+log(0.9))) reduce_sum也能在某个axis上进行计算： 123456789101112131415161718a = tf.constant(np.array([ [1, 2, 3], [4, 5, 6]]))print(a.shape)b = tf.reduce_sum(a)c = tf.reduce_sum(a, axis=0)d = tf.reduce_sum(a, axis=1)with tf.Session() as sess: print(sess.run(b)) print(sess.run(c)) print(sess.run(d))# Output:(2, 3)21[5 7 9][ 6 15] 默认情况下，reduce_sum会对所有axis进行计算，得到的结果是一个标量。在上面的例子里，由于a的shape是(2, 3)， 所以，当对axis=0进行计算时，结果的shape为(3,)，当对axis=1进行计算时，结果的shape为(2,)。对某个axis进行计算时，结果的shape就是把源的shape的axis为索引所在位置的值去掉，剩余的结果就是结果的shape。 接下来就是训练过程： 1234567891011121314151617init = tf.global_variables_initializer()train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)with tf.Session() as sess: sess.run(init) for i in range(1000): batch = np.random.choice(np.arange(60000), 100) tx, ty = train_images[batch], train_labels[batch] sess.run(train, feed_dict=&#123;X: tx, Y: ty&#125;) if (i + 1) % 50 == 0: print("Epoch:", i + 1, "Cost:", sess.run(cost, feed_dict=&#123; X: train_images, Y: train_labels&#125;)) # test model correct = tf.equal(tf.argmax(Y, 1), tf.argmax(y, 1)) accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) print("Accuracy:", sess.run(accuracy, feed_dict=&#123;X: test_images, Y: test_labels&#125;)) 为了加快训练速度，每轮迭代时并不使用所有数据集进行训练，而是每次随机选取一部分数据集进行训练（随机梯度下降）。 tf.argmax可以获取指定维度的最大值所在的索引；tf.cast可以转换dtype。 经过以上的训练过程，最终得到的准确率大概是91%，效果还行，大部分的预计是正确的，也会偶尔出现错误：]]></content>
  </entry>
  <entry>
    <title><![CDATA[awk命令学习笔记]]></title>
    <url>%2Fp%2F7hpz5%2F</url>
    <content type="text"><![CDATA[执行流程awk命令基本结构： 1awk 'BEGIN&#123; commands &#125; pattern &#123; commands &#125; END&#123; commands &#125;' file 【选项】 -F：输入域分隔符 -v：自定义变量 -f：调用awk脚本 【执行流程】 (1) 执行BEGIN{ commands }； (2) 从文件或stdin中读取一行，执行pattern { commands }。重复这个过程直至读取完毕； (3) 执行END{ commands } 特殊变量NR：记录数量，也就是已读的行号 NF：字段数量 $0：当前行文本 $1：第一个字段的文本 FS：输入域分隔符 OFS：输出域分隔符 pattern/pattern/：仅处理匹配的行；!/pattern/：仅处理不匹配的行 pattern部分也可以是条件。例如： 123$ awk -F : 'NR&lt;3' /etc/passwdroot:x:0:0:root:/root:/usr/bin/zshdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin 数组awk的数组使用方式有点特别。awk数组是关联数组，引用不存在的索引时会自动使用默认值。 12$ echo | awk '&#123;arr[0]++;print arr[0], arr[1], arr[2]==0&#125;'1 1 内置函数printf(...)：格式化输出； length(s)：字符串长度; gsub(r, s, [t])：在t字符串搜索r匹配的内容并全部替换为s getline：读取一行（文件游标也会移动一行） 其它语法awk支持if语句、switch语句、while循环、for循环、for in 循环。 awk支持算数、赋值、比较、逻辑和模式匹配运算符。 ~：匹配；!~：不匹配]]></content>
  </entry>
  <entry>
    <title><![CDATA[MNIST数据集解析]]></title>
    <url>%2Fp%2F7hnmu%2F</url>
    <content type="text"><![CDATA[从MNIST数据集官网可以下载MNIST数据集。 MNIST数据集以.gz格式压缩，Python可以直接读取而不需要解压缩： 1234import gzipwith gzip.open('t10k-images-idx3-ubyte.gz') as f: buf = f.read() MNIST数据集使用二进制文件，而不是常规的图片文件格式。以t10k-images-idx3-ubyte为例，在官网有其结构说明： 123456789[offset] [type] [value] [description] 0000 32 bit integer 0x00000803(2051) magic number 0004 32 bit integer 10000 number of images 0008 32 bit integer 28 number of rows 0012 32 bit integer 28 number of columns 0016 unsigned byte ?? pixel 0017 unsigned byte ?? pixel ........ xxxx unsigned byte ?? pixel 先解压并查看t10k-images-idx3-ubyte的内容： 123456789101112$ gzip -d -k t10k-images-idx3-ubyte.gz$ xxd t10k-images-idx3-ubyte | head00000000: 0000 0803 0000 2710 0000 001c 0000 001c ......'.........00000010: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000020: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000030: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000040: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000050: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000060: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000070: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000080: 0000 0000 0000 0000 0000 0000 0000 0000 ................00000090: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 最开始4个字节是魔数，16进制为0x00000803，从结果可以看出确实如此。随后的4个字节为图片的数量，值为10000，16进制为0x2710。可以通过Linux自带的计算器bc来计算，ibase和obase分别为输入和输出的进制： 12345$ bc -qibase=10obase=16100002710 那么，在Python中要怎么解析二进制数据呢？可以使用struct模块来读取二进制文件： 123456import structmagic, images, rows, columns = struct.unpack_from('&gt;iiii', buf, 0)print(magic, images, rows, columns)# Output：2051 10000 28 28 在MNIST官网对数据集的格式有这样的一句说明：“All the integers in the files are stored in the MSB first (high endian) format used by most non-Intel processors. Users of Intel processors and other low-endian machines must flip the bytes of the header.”。意思是，所有的整数使用MSB方式（也就是大端模式）。大小端模式是数据在地址上的存放方式。大端模式高字节保存在低地址中，小端模式反之。 &gt;iiii的意思就是：大端模式，读取四个int（C语言）。参见Python struct模块官方文档 来读取第一张图片试试： 12345678from PIL import Imageidx = struct.calcsize('&gt;iiii')img = Image.new('L', (columns, rows))for i in range(rows): for j in range(columns): img.putpixel((j, i), int(struct.unpack_from('B', buf, idx)[0])) idx += struct.calcsize('B') 在MNIST官网对于像素的格式有这样的说明：“Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black). ”。 Image.new()第一个参数是模式，由于MNIST数据集是灰度图像，所以是L，第二个参数是尺寸(宽, 高)。由于像素是按行排列，也就是第一个像素坐标是(0, 0)，第二个像素坐标是(1, 0)，第三个像素坐标是(2, 0)，以此类推。坐标(x, y)以左上角为原点。 如果使用Jupyter notebook，可以使用内联matplotlib来显示图片： 12345import matplotlib.pyplot as pltimport numpy as np%matplotlib inlineplt.imshow(np.asarray(img), cmap=plt.cm.gray) 至于其余的文件解析，在此就不赘述了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用TensorFlow进行线性回归]]></title>
    <url>%2Fp%2F7hmgi%2F</url>
    <content type="text"><![CDATA[我们先随机生成一些数据： 1234import numpy as nptrain_X = 20 * np.random.rand(100).astype(np.float32)train_Y = (30 * train_X + 100 + 10 * np.random.randn(100)).astype(np.float32) 预期拟合的函数为： Y = 30 X + 100现在我们使用线性回归，假设拟合的函数为： y = W x + b先给W、b赋初值，然后计算y和实际值的差距，并使用梯度下降算法来减小差距。定义这个差距（损失函数）为： C = \frac 1 {2m} \sum _{i=1} ^{m} (Y_i - y_i)^2现在使用TensorFlow来完成。 首先定义变量： 12345678import tensorflow as tfW = tf.Variable(1.0)b = tf.Variable(0.0)X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)y = tf.add(tf.multiply(W, X), b)cost = tf.reduce_sum(tf.pow(Y-y, 2))/(2*train_X.shape[0]) W、b是待训练的参数，使用tf.Variable；X、Y接收输入的数据，使用tf.placeholder。 然后开始训练： 123456789101112init = tf.global_variables_initializer()train = tf.train.GradientDescentOptimizer(0.2).minimize(cost)with tf.Session() as sess: sess.run(init) for i in range(100): for tx, ty in zip(train_X, train_Y): sess.run(train, feed_dict=&#123;X: tx, Y: ty&#125;) if (i+1) % 10 == 0: c = sess.run(cost, feed_dict=&#123;X: train_X, Y: train_Y&#125;) print('epoch: %d cost:%f y = %f x + %f' % (i + 1, c, sess.run(W), sess.run(b))) 可以看到，拟合的结果还不错。]]></content>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow基础入门]]></title>
    <url>%2Fp%2F7hmah%2F</url>
    <content type="text"><![CDATA[TensorFlow安装CPU版本直接pip install tf-nightly即可。 GPU版本需要安装显卡驱动、cuda、cudnn，注意版本。若手动安装cuda还要将cuda的lib64目录加入LD_LIBRARY_PATH环境变量。然后使用pip install tf-nightly-gpu安装即可。 在Python中一般使用 1import tensorflow as tf 来import tensorflow。 Graph（计算图）Graph是TensorFlow的基本计算模型。TensorFlow会维护一个默认的计算图，可以通过tf.get_default_graph()来获取当前默认的计算图。通过tf.Graph()可以创建计算图。 Session（会话）通过Session来执行定义好的计算。使用会话一般有两种模式： 12345678# 第一种sess = tf.Session()sess.run(...)sess.close()# 第二种with tf.Session() as sess: sess.run(...) Tensor（张量）Tensor主要有三个属性：name、shape、dtype。 name的形式为&lt;op_name&gt;:&lt;output_index&gt;，op_name为节点名，output_index为该张量是计算节点输出的第几个结果（从0开始）。 Tensor用于引用中间计算结果和获得计算结果。 constantconstant就是常量，在创建时赋初值且值不再变化。 12345&gt;&gt;&gt; a = tf.constant(5, name='a')&gt;&gt;&gt; a&lt;tf.Tensor 'a:0' shape=() dtype=int32&gt;&gt;&gt;&gt; tf.Session().run(a)5 VariableVariable一般用于保存和更新神经网络中的参数。可以使用assign为Variable赋值。 Variable在使用前要使用initializer进行初始化，使用tf.global_variables_initializer()可以初始化所有变量（注意：需要在Session中run一下这个初始化操作！） 123456789101112state = tf.Variable(0)one = tf.constant(1)add = tf.add(state, one)opt = tf.assign(state, add)init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for _ in range(10): sess.run(opt) print(sess.run(state)) placeholderplaceholder是占位符，用来提供输入数据。通过sess.run()的feed_dict参数为placeholder传入值。 12feed = tf.placeholder(tf.float32)print(tf.Session().run(feed, feed_dict=&#123;feed: 3.0&#125;))]]></content>
  </entry>
  <entry>
    <title><![CDATA[OpenCV拼接全景图]]></title>
    <url>%2Fp%2F7hldu%2F</url>
    <content type="text"><![CDATA[OpenCV自带了图像拼接算法stitch，而且效果还不错。 12345678910111213import globimport cv2st = cv2.createStitcher()STITCH_DIR = '/home/wjmr/GitHub/opencv_extra/testdata/stitching/'imgs = [cv2.imread(f) for f in glob.glob(STITCH_DIR + 'boat*')]result = st.stitch(imgs)cv2.imwrite("result.jpg", result[1])cv2.namedWindow('demo', cv2.WINDOW_GUI_NORMAL)cv2.imshow('demo', cv2.imread('result.jpg'))cv2.waitKey(0)cv2.destroyAllWindows() 使用了opencv_extra里的图片。]]></content>
  </entry>
  <entry>
    <title><![CDATA[gimp练习：Disintegration Effect]]></title>
    <url>%2Fp%2F7gnm9%2F</url>
    <content type="text"><![CDATA[在Youtube上看到了一个Gimp教程：GIMP Tutorial: Disintegration Effect，就来练习一下。 打开模特的照片，如果我们系统的Gtk主题是亮色的，画布衬垫可能是白色的，这样就和模特照片的白色混在一起了。因此，建议在 首选项&gt;图像窗口&gt;外观 修改画布衬垫模式。 首先，模特照片的颜色有点灰，因此可以调整下色阶： 然后，复制图层，对下面的图层应用 滤镜&gt;扭曲&gt;交互式翘曲(IWarp)： 对于复制的图层，以模特的背景色（白色）为前景色，选择碎片状的笔刷，以合适的大小，画出边缘碎裂的效果（如图）： 然后添加白色的蒙板，用以黑色为前景色，补上更远处的碎片。其实这里用的是下面扭曲的部分： 大体的效果已经出来了，然后就是补上裂纹的效果。 添加裂纹图片，然后调整到合适的位置和大小，应用阈值，提升纹路效果： 然后视频里使用按颜色选择工具，将白色部分抠去，然后反相。其实可以反相然后修改图层混合模式就行，这里我选择的是仅变亮： 之后再使用蒙板将不需要的地方擦掉即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Docker基础学习笔记]]></title>
    <url>%2Fp%2F7gf9c%2F</url>
    <content type="text"><![CDATA[Docker基本使用docker search 搜索镜像 docker pull REPOSITORY[:TAG] 获取镜像 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 运行Docker容器。（如果本地没有镜像会自动从仓库获取） -d 后台运行 -P 容器端口随机映射到宿主机 -p 宿主机端口:容器端口 端口绑定 -i 启动一个可交互容器 -t 使用虚拟终端关联到容器的标准输入输出 -v 宿主机目录:容器目录 挂载数据卷 --rm 使用后销毁 docker ps 查看Docker容器信息（默认只看正在运行的） -a 查看所有容器 其它命令 docker port 查看容器的端口映射情况 docker logs 查看容器的日志 -f可以持续输出log信息 docker top 查看容器的进程 docker inspect 查看容器底层信息，返回一个json docker stop 停止容器 docker rm 删除容器（需要先停止） docker rmi 删除镜像 docker images 列出本地主机上的镜像 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 提交对容器的修改，创建新镜像 docker build 构建镜像 docker tag 设置镜像标签 Docker与虚拟机很多人喜欢把Docker解释为轻量级虚拟机，这往往使人困惑。Docker容器是宿主机上的进程，是Docker Daemon的子进程，通过Namespace实现容器间的进程隔离。Namespace还有网络隔离、使容器有独立主机名，从而使得容器可视为独立节点。Docker容器利用chroot，形成了独立的运行环境。 DockerfileFROM 指定基础镜像 RUN 执行命令 COPY 复制文件 CMD 指定默认的容器主进程的启动命令 ENV 设置环境变量 VOLUME 定义匿名数据卷 EXPOSE 声明端口 WORKDIR 指定工作目录 Docker ComposeDocker Compose用于运行多个Docker容器，使用YAML文件作为配置文件，文件名一般是docker-compose.yml。YAML文件使用缩进来表示层级关系，在编写时需要注意。 Docker Compose详细配置 docker-compose up 用Compose启动应用 docker-compose stop 用Compose停止应用 docker-compose down 用Compose移除容器 --volumes 连同数据卷也移除 Docker Machine使用VirtualBox驱动创建Docker主机：docker-machine create --driver virtualbox &lt;machine-name&gt; 启动Docker主机：docker-machine start &lt;machine-name&gt; 停止Docker主机：docker-machine stop &lt;machine-name&gt; SSH连接Docker主机：docker-machine ssh &lt;machine-name&gt; 在Docker主机中执行命令：docker-machine ssh &lt;machine-name&gt; &quot;&lt;在Docker主机中执行的命令&gt;&quot; 查看Docker主机：docker-machine ls swarm集群与负载均衡初始化swarm集群管理节点：docker swarm init --advertise-addr &lt;ip&gt;:&lt;port&gt;（ ip 通过docker-machine ls得到, port 一般是2377） 加入集群，作为工作节点：docker swarm join --token &lt;token&gt; &lt;ip&gt;:&lt;port&gt;（token 在初始化管理节点时会显示） 查看集群中的节点：docker node ls 部署应用：docker stack deploy -c docker-compose.yml &lt;app-name&gt; 清除应用：docker stack rm &lt;app-name&gt; 离开swarm：docker swarm leave（管理节点离开swarm需要加上-f/--force参数以强制离开） 部署dockersamples/visualizer:stable服务可以在浏览器可视化集群。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux使用crontab设定计划任务]]></title>
    <url>%2Fp%2F7gbw9%2F</url>
    <content type="text"><![CDATA[crontab命令用法crontab -e 编辑计划任务 crontab -l 列出计划任务 crontab -r 移除计划任务 使用select-editor命令可以选择编辑器，也可以通过EDITOR环境变量来设置默认编辑器： 1export EDITOR=/usr/bin/vim 基本原理是系统每分钟检查下crontab，然后执行生效的任务。 计划任务格式12* * * * * command分 时 日 月 周 命令 【示例】 30 23 * * * command 每天23:30运行 0 10-21/2 * * * command 每天10:00~21:00每隔2小时运行 【符号说明】 * 所有值(每) , 列举（和） - 范围（至） / 间隔（每隔） 注意要点在 crontab 可以设置环境变量，如PATH等。 如果需要运行 GUI 程序，设置DISPLAY=:0。 如果要用终端模拟器执行某个脚本（这样可以看到脚本执行过程），命令可以写： 1x-terminal-emulator -x 脚本文件名 x-terminal-emulator会打开系统默认终端模拟器。 另外，计划任务会在命令执行时向用户发送邮件，可以使用mail命令查看。如果不想收到邮件，可以设置MAILTO=&#39;&#39;。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python单元测试unittest]]></title>
    <url>%2Fp%2F7gbvt%2F</url>
    <content type="text"><![CDATA[执行流程 使用要点一个 testcase 类应该派生自 unittest.TestCase setUpClass()、tearDownClass()必须使用@classmethod装饰器 assertEqual一般first是预期值，second是实际值。 断言抛出异常 12with self.assertRaises(SomeException): do_something() assertTrue、assertFalse assertTrue实际上是断言 bool(expr) 为 True 。同理，assertFalse实际上是断言 bool(expr) 为 False 。因此，若要断言 expr 为 True 或 False，不要用assertTrue或assertFalse。 命令行执行unittest 123456# 运行test_modulepython -m unittest test_module# 运行TestClasspython -m unittest test_module.TestClass# 运行test_methodpython -m unittest test_module.TestClass.test_method]]></content>
  </entry>
  <entry>
    <title><![CDATA[安装ArchLinux成功，纪念一下]]></title>
    <url>%2Fp%2F7fbfe%2F</url>
    <content type="text"><![CDATA[ArchLinux是一个人气较高的发行版，安装起来比较麻烦。不过，在知道了挂载、X等内容再看ArchLinux的wiki，会觉得不是很难。 由于ArchLinux需要在线安装，所以能联网很重要。对于有线连接，需要启用dhcpcd。 建立分区、格式化分区比较容易理解，毕竟Windows上也有这些操作。至于挂载分区，可以理解为提供一个访问路径。在安装系统时，进入的是ArchLinux的Live系统，而要在硬盘上安装系统，就要把硬盘上的分区挂载到Live系统。一般把根目录挂载到/mnt，然后安装基本系统、生成fstab，系统启动时会读取fstab并根据fstab中的配置自动挂载分区。之后chroot到/mnt，也就是把/mnt作为根目录，由于我们把ArchLinux挂载到了/mnt，这一步也就相当于进入在硬盘上安装的ArchLinux。 之后就是设置Locale、主机名、Root密码等，这些比较简单。然后还要安装引导程序（Bootloader），grub用的多点。 下面说下Linux下的图形界面。Linux本来是没有图形界面的，Linux也可以没有图形界面，图形界面是运行在Linux上的程序。图形界面一般是通过XServer或Wayland实现，前者目前应用广泛，后者是趋势，这些都是显示服务协议。客户端运行GUI程序，服务端负责显示GUI程序。这两个协议的区别在于前者是服务端绘制窗口，后者是客户端绘制。 xorg是X11协议的开源实现，因此需要先安装xorg。如果要系统启动时开启X，可以安装显示管理器（如LightDM等）。另外，还需要安装桌面环境或窗口管理器。桌面环境（如KDE、GNOME、Xfce等）类似于Windows，提供了各种窗口部件，以及必要的窗口程序（如文件管理器、虚拟终端等），桌面环境一般包含了显示管理器、窗口管理器。窗口管理器（如i3等）则更为轻量，可以控制窗口的位置、大小等。 由此可见，ArchLinux是高度可定制的，可以根据自己的喜好对系统进行配置，贯彻了其KISS哲学。不过，这样导致上手复杂，而且安装配置会消耗大量的时间，于是就有了Manjaro等ArchLinux衍生版。另外，Linux拥有相当多的发行版，还有各种桌面环境，造成了Linux碎片化严重。Linux是拿来用的，不是拿来折腾的。折腾Linux固然可以学习不少东西，但倘若沉醉于折腾Linux，就有点舍本逐末了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL基础]]></title>
    <url>%2Fp%2F7fa9t%2F</url>
    <content type="text"><![CDATA[MySQL环境搭建安装MySQL：sudo apt install mysql-server mysql-client 验证MySQL已启动：sudo netstat -anp | grep mysql 启动MySQL（三种均可）：123sudo service mysql startsudo /etc/init.d/mysql startsudo systemctl start mysql.service 查看MySQL运行状态（三种均可）：123service mysql status/etc/init.d/mysql statussystemctl status mysql.service MySQL基础使用数据库操作查看数据库：SHOW DATABASES; 连接数据库：USE 数据库名 新建数据库：CREATE DATABASE 数据库名; 删除数据库：DROP DATABASE 数据库名; 加载文件中的数据：SOURCE 文件名（一般是.sql后缀） 退出：QUIT 或者 EXIT 表操作查看表：SHOW TABLES; 新建数据表：123456CREATE TABLE 表的名字( 列名a 数据类型(数据长度), 列名b 数据类型(数据长度), 列名c 数据类型(数据长度)); 查看表：SELECT * FROM 表的名字; 插入数据：INSERT INTO 表的名字(列名a, 列名b, 列名c) VALUES(值1, 值2, 值3); 重命名表（三种均可）：123RENAME TABLE 原名 TO 新名;ALTER TABLE 原名 RENAME [TO ]新名;删除表 DROP TABLE 表的名字; 增加一列： 1ALTER TABLE 表的名字 ADD [COLUMN ]列名字 数据类型 约束[ AFTER 列名字| FIRST]; 默认增加在最后一列，AFTER指定在某列后插入，FIRST指定插入第一列 删除一列：ALTER TABLE 表的名字 DROP [COLUMN ]列名字; 修改一列： 1ALTER TABLE 表的名字 CHANGE 原列名 新列名 数据类型 约束; 可以修改列名、数据类型或约束；数据类型不能省略，否则重命名失败；修改数据类型可能导致数据丢失。 1ALTER TABLE 表的名字 MODIFY 列名字 新数据类型; 可以修改数据类型。 修改表中的值：UPDATE 表的名字 SET 列1=值1,列2=值2 WHERE 条件; 删除记录：DELETE FROM 表的名字 WHERE 条件; MySQL常用数据类型 数据类型 大小（字节） 说明 INT 4 整数 FLOAT 4 单精度浮点数 DOUBLE 8 双精度浮点数 ENUM 枚举，单选，如性别：enum(‘a’,’b’) SET 集合，多选：set(‘1’, ‘2’, ‘3’) DATE 3 日期：YYYY-MM-DD TIME 3 时间：HH:MM:SS YEAR 1 年份值：YYYY CHAR 0~255 定长字符串 VARCHAR 0~255 变长字符串 TEXT 0~65536 长文本数据 CHAR和VARCHAR的区别：例如存储”abc”, CHAR(10)占10字节（包括7个空字符） VARCHAR(12)占4字节（增加一个额外字节来存储字符串本身的长度） SQL的约束PRIMARY KEY 主键 DEFAULT 默认值 UNIQUE 唯一：一张表中指定一列的值不能有重复，即这一列每个值都是唯一的 FOREIGN KEY(两种均可) [CONSTRAINT 约束名 ]FOREIGN KEY (外键名) REFERENCES 表的名字(主键) NOT NULL 非空 SELECT语句1SELECT 要查询的列名 FROM 表的名字 WHERE 限制条件; 要查询的列名为*代表查询所有列 WHERE限制条件可以有数学符号 = &lt; &gt; &gt;= &lt;= 限制条件之间可以有逻辑关系 AND OR x&gt;=25 AND x&lt;=30 等价于 x BETWEEN 25 AND 30 IN与NOT IN 用于筛选在或不在某个范围内的结果（类似Python） LIKE 模糊搜索，使用通配符： _代表一个字符 % 代表若干个字符 ORDER BY 键名 ASC/DESC 对键进行升序/降序排序 SQL内置函数计算： 函数 COUNT SUM AVG MAX MIN 作用 计数 求和 平均值 最大值 最小值 AS 给值重命名 子查询类似于函数嵌套 【示例】 123SELECT of_dpt,COUNT(proj_name) AS count_project FROM projectWHERE of_dpt IN(SELECT in_dpt FROM employee WHERE name='Tom'); 连接查询JOIN 将两个表拼接， ON 规定连接规则 【示例】 1234SELECT id,name,people_numFROM employee,departmentWHERE employee.in_dpt = department.dpt_nameORDER BY id; 等价于 1234SELECT id,name,people_numFROM employee JOIN departmentON employee.in_dpt = department.dpt_nameORDER BY id; 其他基本操作索引创建索引（两种均可）： 12ALTER TABLE 表的名字 ADD INDEX 索引名(列名);CREATE INDEX 索引名 ON 表名字(列名); 查看索引：SHOW INDEX FROM 表的名字; 视图视图是一种虚拟存在的表，数据来自原来的表中。 创建视图：CREATE VIEW 视图名(列a,列b,列c) AS SELECT 列1,列2,列3 FROM 表的名字; 创建视图的语句后半句是一个SELECT查询语句，因此视图也可以建立在多张表上（使用子查询或连接查询） 导入导出数据导入数据：LOAD DATA INFILE &#39;文件名&#39; INTO TABLE 表的名字; 导出数据：SELECT 列1,列2 INTO OUTFILE &#39;文件名&#39; FROM 表的名字; 备份与恢复备份与导出的区别：导出的文件只是保存数据库中的数据；而备份，则是把数据库的结构，包括数据、约束、索引、视图等全部另存为一个文件。 使用mysqldump备份: 12mysqldump -u 用户 -p 密码 数据库名&gt;备份文件名mysqldump -u 用户 -p 密码 数据库名 表的名字&gt;备份文件名 备份文件名一般是.sql后缀 恢复： 使用source恢复 source 文件名 使用&lt;恢复 运行命令：mysql -u 用户 -p 密码 数据库名 &lt; 文件名]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据可视化之matplotlib]]></title>
    <url>%2Fp%2F7e0au%2F</url>
    <content type="text"><![CDATA[架构 Artist是图像上所有可见元素的基类，以对象的方式对可见元素进行描述。 图像渲染依赖于Backend，Backend作为后端绘图渲染引擎，支持GUI方式（直接将图像显示在屏幕上，如GTK、WX等）与非GUI方式（输出为某种格式的文件，如PS、AGG等）。 获取与设置Backend： 123456&gt;&gt;&gt; import matplotlib as mpl&gt;&gt;&gt; mpl.get_backend()'TkAgg'&gt;&gt;&gt; mpl.use('agg')&gt;&gt;&gt; mpl.get_backend()'agg' 创建Figure： 123456&gt;&gt;&gt; import matplotlib.pyplot as plt&gt;&gt;&gt; plt.figure()&lt;matplotlib.figure.Figure object at 0x7fc6b845ccc0&gt; &gt;&gt;&gt; fig = plt.gcf()&gt;&gt;&gt; fig.get_children()[&lt;matplotlib.patches.Rectangle object at 0x7fc6945d5390&gt;] 使用plt.figure()会创建并返回一个Figure对象。Figure是绘图区，所有的绘图操作都在Figure里进行。使用plt.gcf()可以获取当前的Figure。 为了绘图，我们可以先创建Axes： 1234567891011121314151617&gt;&gt;&gt; plt.axes()&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fc68cbd3048&gt; &gt;&gt;&gt; ax = plt.gca()&gt;&gt;&gt; ax.get_children()[&lt;matplotlib.spines.Spine object at 0x7fc68cbd3438&gt;, &lt;matplotlib.spines.Spine object at 0x7fc68cbd3550&gt;, &lt;matplotlib.spines.Spine object at 0x7fc68cbd3668&gt;, &lt;matplotlib.spines.Spine object at 0x7fc68cbd3780&gt;, &lt;matplotlib.axis.XAxis object at 0x7fc68cbd3860&gt;, &lt;matplotlib.axis.YAxis object at 0x7fc68cbedeb8&gt;, Text(0.5,1,''), Text(0,1,''), Text(1,1,''), &lt;matplotlib.patches.Rectangle object at 0x7fc68bc48a20&gt;]&gt;&gt;&gt; fig.get_children()[&lt;matplotlib.patches.Rectangle object at 0x7fc6945d5390&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fc68cbd3048&gt;] 使用plt.axes()会创建并返回一个Axes对象。Axes是坐标轴区域，默认包括Spine、Axis、标题和一个绘图区域。 Axis是坐标轴，包括Tick（刻度）和标签。Spine是轴线（如图中红线）： 【Tip】 可以设置风格： 1plt.style.use('seaborn') 查看可用风格： 1print(plt.style.available) 2D绘图常用操作创建Figure，创建subplot： 12fig = plt.figure()ax = plt.subplot() 可以合为一步： 1fig, ax = plt.subplots() 即使没有事先创建Figure和subplot，也会自动创建。 plot绘制折线图常用参数： 参数 解释 color 颜色 linestyle 线型 linewidth 线条宽度 alpha 透明度 label 标签（制作图例时用到） marker 标记点类型 markerfacecolor 标记点颜色 markersize 标记点大小 示例： 12345678910from matplotlib import pyplot as pltimport numpy as npX = np.linspace(-2 * np.pi, 2 * np.pi, 1000)y1 = np.sin(X)y2 = np.cos(X)plt.plot(X, y1, color='r', linestyle='--', linewidth=2, alpha=0.8)plt.plot(X, y2, color='b', linestyle='-', linewidth=2)plt.show() scatter绘制散点图常用参数： 参数 解释 s 散点大小 c 散点颜色 edgecolors 散点边缘颜色 marker 散点样式 cmap 定义多类别散点的颜色 alpha 透明度 示例： 12345678910from matplotlib import pyplot as pltimport numpy as npx = np.random.rand(100)y = np.random.rand(100)colors = np.random.rand(100)size = np.random.normal(20, 30, 100)plt.scatter(x, y, s=size, c=colors)plt.show() 其它 命令 图类型 pie 饼图 bar 条形图 hist 柱状图 barh 直方图 contour 等高线图 imshow 显示图像 … … 子图绘制1、使用plt.subplot 1plt.subplot(nrows, ncols, plot_number) nrows: 将行进行n等分 ncols: 将列进行n等分 plot_number: 序号（从1开始，从左到右，从上到下，依次递增） 如果出现重叠区域，则会覆盖之前的。 示例： 1234567891011121314151617181920import numpy as npimport matplotlib.pyplot as pltx1 = np.linspace(0.0, 5.0)x2 = np.linspace(0.0, 2.0)y1 = np.cos(2 * np.pi * x1) * np.exp(-x1)y2 = np.cos(2 * np.pi * x2)plt.subplot(2, 1, 1)plt.plot(x1, y1, 'o-')plt.title('A tale of 2 subplots')plt.ylabel('Damped oscillation')plt.subplot(2, 1, 2)plt.plot(x2, y2, '.-')plt.xlabel('time (s)')plt.ylabel('Undamped')plt.show() 2、使用plt.axes 1plt.axes(*args, **kwargs) 向plt.axes传入一个数组[left, bottom, width, height]（归一化），设置axes范围。 示例： 1234567891011121314import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-2 * np.pi, 2 * np.pi)y1 = np.sin(x)y2 = np.cos(x)plt.axes([.1, .1, .8, .8])plt.plot(x, y1, 'k')plt.axes([.6, .6, .3, .3])plt.plot(x, y2, 'r')plt.show()]]></content>
  </entry>
  <entry>
    <title><![CDATA[Numpy使用教程（二）]]></title>
    <url>%2Fp%2F7dvvr%2F</url>
    <content type="text"><![CDATA[numpy随机抽样随机数生成 numpy.random.rand(d0, d1, ..., dn) 方法的作用为：指定一个数组，并使用 [0, 1) 区间随机数据填充，这些数据均匀分布。 123456In [1]: import numpy as npIn [2]: np.random.rand(2,3)Out[2]: array([[ 0.09887339, 0.75074537, 0.9944429 ], [ 0.92790081, 0.84365033, 0.3087985 ]]) numpy.random.randn(d0, d1, ..., dn): 返回符合标准正态分布的随机数据 numpy.random.randint(low, high, size, dtype)： 返回[low, high)的随机整数 numpy.random.random_integers(low, high, size): 返回[low, high]的随机整数 numpy.random.random_sample(size): 在[0,1)区间生成指定size的随机浮点数与之类似的方法还有： numpy.random.random([size]) numpy.random.ranf([size]) numpy.random.sample([size]) numpy.random.choice(a, size, replace, p): 在给定的一维数组里生成随机数 概率密度分布 numpy.random.beta(a，b，size)：从 Beta 分布中生成随机数。 numpy.random.binomial(n, p, size)：从二项分布中生成随机数。 numpy.random.chisquare(df，size)：从卡方分布中生成随机数。 numpy.random.dirichlet(alpha，size)：从 Dirichlet 分布中生成随机数。 numpy.random.exponential(scale，size)：从指数分布中生成随机数。 numpy.random.f(dfnum，dfden，size)：从 F 分布中生成随机数。 numpy.random.gamma(shape，scale，size)：从 Gamma 分布中生成随机数。 numpy.random.geometric(p，size)：从几何分布中生成随机数。 numpy.random.gumbel(loc，scale，size)：从 Gumbel 分布中生成随机数。 numpy.random.hypergeometric(ngood, nbad, nsample, size)：从超几何分布中生成随机数。 numpy.random.laplace(loc，scale，size)：从拉普拉斯双指数分布中生成随机数。 numpy.random.logistic(loc，scale，size)：从逻辑分布中生成随机数。 numpy.random.lognormal(mean，sigma，size)：从对数正态分布中生成随机数。 numpy.random.logseries(p，size)：从对数系列分布中生成随机数。 numpy.random.multinomial(n，pvals，size)：从多项分布中生成随机数。 numpy.random.multivariate_normal(mean, cov, size)：从多变量正态分布绘制随机样本。 numpy.random.negative_binomial(n, p, size)：从负二项分布中生成随机数。 numpy.random.noncentral_chisquare(df，nonc，size)：从非中心卡方分布中生成随机数。 numpy.random.noncentral_f(dfnum, dfden, nonc, size)：从非中心 F 分布中抽取样本。 numpy.random.normal(loc，scale，size)：从正态分布绘制随机样本。 numpy.random.pareto(a，size)：从具有指定形状的 Pareto II 或 Lomax 分布中生成随机数。 numpy.random.poisson(lam，size)：从泊松分布中生成随机数。 numpy.random.power(a，size)：从具有正指数 a-1 的功率分布中在 0，1 中生成随机数。 numpy.random.rayleigh(scale，size)：从瑞利分布中生成随机数。 numpy.random.standard_cauchy(size)：从标准 Cauchy 分布中生成随机数。 numpy.random.standard_exponential(size)：从标准指数分布中生成随机数。 numpy.random.standard_gamma(shape，size)：从标准 Gamma 分布中生成随机数。 numpy.random.standard_normal(size)：从标准正态分布中生成随机数。 numpy.random.standard_t(df，size)：从具有 df 自由度的标准学生 t 分布中生成随机数。 numpy.random.triangular(left，mode，right，size)：从三角分布中生成随机数。 numpy.random.uniform(low，high，size)：从均匀分布中生成随机数。 numpy.random.vonmises(mu，kappa，size)：从 von Mises 分布中生成随机数。 numpy.random.wald(mean，scale，size)：从 Wald 或反高斯分布中生成随机数。 numpy.random.weibull(a，size)：从威布尔分布中生成随机数。 numpy.random.zipf(a，size)：从 Zipf 分布中生成随机数。 数学函数三角函数 numpy.sin(x)：三角正弦。 numpy.cos(x)：三角余弦。 numpy.tan(x)：三角正切。 numpy.arcsin(x)：三角反正弦。 numpy.arccos(x)：三角反余弦。 numpy.arctan(x)：三角反正切。 numpy.hypot(x1,x2)：直角三角形求斜边。 numpy.degrees(x)：弧度转换为度。 numpy.radians(x)：度转换为弧度。 numpy.deg2rad(x)：度转换为弧度。 numpy.rad2deg(x)：弧度转换为度。 双曲函数 numpy.sinh(x)：双曲正弦。 numpy.cosh(x)：双曲余弦。 numpy.tanh(x)：双曲正切。 numpy.arcsinh(x)：反双曲正弦。 numpy.arccosh(x)：反双曲余弦。 numpy.arctanh(x)：反双曲正切。 数值修约 numpy.around与numpy.round_等价，四舍六入五取偶。 123&gt;&gt;&gt; a = np.array([1.4, 1.5, 1.6, 2.4, 2.5, 2.6])&gt;&gt;&gt; np.around(a, 0)array([ 1., 2., 2., 2., 2., 3.]) numpy.around(a)：平均到给定的小数位数。 numpy.round_(a)：将数组舍入到给定的小数位数。 numpy.rint(x)：修约到最接近的整数。 numpy.fix(x, y)：向 0 舍入到最接近的整数。 numpy.floor(x)：返回输入的底部(标量 x 的底部是最大的整数 i)。 numpy.ceil(x)：返回输入的上限(标量 x 的底部是最小的整数 i). numpy.trunc(x)：返回输入的截断值。 求和、求积、差分 numpy.prod(a, axis, dtype, keepdims)：返回指定轴上的数组元素的乘积。 numpy.sum(a, axis, dtype, keepdims)：返回指定轴上的数组元素的总和。 numpy.nanprod(a, axis, dtype, keepdims)：返回指定轴上的数组元素的乘积, 将 NaN 视作 1。 numpy.nansum(a, axis, dtype, keepdims)：返回指定轴上的数组元素的总和, 将 NaN 视作 0。 numpy.cumprod(a, axis, dtype)：返回沿给定轴的元素的累积乘积。 numpy.cumsum(a, axis, dtype)：返回沿给定轴的元素的累积总和。 numpy.nancumprod(a, axis, dtype)：返回沿给定轴的元素的累积乘积, 将 NaN 视作 1。 numpy.nancumsum(a, axis, dtype)：返回沿给定轴的元素的累积总和, 将 NaN 视作 0。 numpy.diff(a, n, axis)：计算沿指定轴的第 n 个离散差分。 numpy.ediff1d(ary, to_end, to_begin)：数组的连续元素之间的差异。 numpy.gradient(f)：返回 N 维数组的梯度。 numpy.cross(a, b, axisa, axisb, axisc, axis)：返回两个(数组）向量的叉积。 numpy.trapz(y, x, dx, axis)：使用复合梯形规则沿给定轴积分。 指数和对数 numpy.exp(x)：计算输入数组中所有元素的指数。 numpy.expm1(x)：对数组中的所有元素计算 exp(x） - 1. numpy.exp2(x)：对于输入数组中的所有 p, 计算 2 ** p。 numpy.log(x)：计算自然对数。 numpy.log10(x)：计算常用对数。 numpy.log2(x)：计算二进制对数。 numpy.log1p(x)：log(1 + x)。 numpy.logaddexp(x1, x2)：log2(2**x1 + 2**x2)。 numpy.logaddexp2(x1, x2)：log(exp(x1) + exp(x2))。 算术运算 numpy.add(x1, x2)：对应元素相加。 numpy.reciprocal(x)：求倒数 1/x。 numpy.negative(x)：求对应负数。 numpy.multiply(x1, x2)：求解乘法。 numpy.divide(x1, x2)：相除 x1/x2。 numpy.power(x1, x2)：类似于 x1^x2。 numpy.subtract(x1, x2)：减法。 numpy.fmod(x1, x2)：返回除法的元素余项。 numpy.mod(x1, x2)：返回余项。 numpy.modf(x1)：返回数组的小数和整数部分。 numpy.remainder(x1, x2)：返回除法余数。 矩阵和向量积 numpy.dot(a,b)：求解两个数组的点积。 numpy.vdot(a,b)：求解两个向量的点积。 numpy.inner(a,b)：求解两个数组的内积。 numpy.outer(a,b)：求解两个向量的外积。 numpy.matmul(a,b)：求解两个数组的矩阵乘积。 numpy.tensordot(a,b)：求解张量点积。 numpy.kron(a,b)：计算 Kronecker 乘积。 其他 numpy.angle(z, deg)：返回复参数的角度。 numpy.real(val)：返回数组元素的实部。 numpy.imag(val)：返回数组元素的虚部。 numpy.conj(x)：按元素方式返回共轭复数。 numpy.convolve(a, v, mode)：返回线性卷积。 numpy.sqrt(x)：平方根。 numpy.cbrt(x)：立方根。 numpy.square(x)：平方。 numpy.absolute(x)：绝对值, 可求解复数。 numpy.fabs(x)：绝对值。 numpy.sign(x)：符号函数。 numpy.maximum(x1, x2)：最大值。 numpy.minimum(x1, x2)：最小值。 numpy.nan_to_num(x)：用 0 替换 NaN。 numpy.interp(x, xp, fp, left, right, period)：线性插值。 代数运算 numpy.linalg.cholesky(a)：Cholesky 分解。 numpy.linalg.qr(a ,mode)：计算矩阵的 QR 因式分解。 numpy.linalg.svd(a ,full_matrices,compute_uv)：奇异值分解。 numpy.linalg.eig(a)：计算正方形数组的特征值和右特征向量。 numpy.linalg.eigh(a, UPLO)：返回 Hermitian 或对称矩阵的特征值和特征向量。 numpy.linalg.eigvals(a)：计算矩阵的特征值。 numpy.linalg.eigvalsh(a, UPLO)：计算 Hermitian 或真实对称矩阵的特征值。 numpy.linalg.norm(x ,ord,axis,keepdims)：计算矩阵或向量范数。 numpy.linalg.cond(x ,p)：计算矩阵的条件数。 numpy.linalg.det(a)：计算数组的行列式。 numpy.linalg.matrix_rank(M ,tol)：使用奇异值分解方法返回秩。 numpy.linalg.slogdet(a)：计算数组的行列式的符号和自然对数。 numpy.trace(a ,offset,axis1,axis2,dtype,out)：沿数组的对角线返回总和。 numpy.linalg.solve(a,b)：求解线性矩阵方程或线性标量方程组。 numpy.linalg.tensorsolve(a,b ,axes)：为 x 解出张量方程a x = b numpy.linalg.lstsq(a,b ,rcond)：将最小二乘解返回到线性矩阵方程。 numpy.linalg.inv(a)：计算逆矩阵。 numpy.linalg.pinv(a ,rcond)：计算矩阵的（Moore-Penrose）伪逆。 numpy.linalg.tensorinv(a ,ind)：计算N维数组的逆。 索引与切片基本格式：ndarray[start:stop:step]，包含start，不包含stop。 12345678910&gt;&gt;&gt; a = np.arange(20).reshape(4,5)&gt;&gt;&gt; aarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]])&gt;&gt;&gt; a[0:3,2:4]array([[ 2, 3], [ 7, 8], [12, 13]]) 排序、搜索、计数排序 1numpy.sort(a, axis=-1, kind='quicksort', order=None) a：数组。 axis：要排序的轴。如果为None，则在排序之前将数组铺平。默认值为 -1，沿最后一个轴排序。 kind：{&#39;quicksort&#39;，&#39;mergesort&#39;，&#39;heapsort&#39;}，排序算法。默认值为 quicksort。 其它排序方法： numpy.lexsort(keys ,axis)：使用多个键进行间接排序。 numpy.argsort(a ,axis,kind,order)：沿给定轴执行间接排序。 numpy.msort(a)：沿第 1 个轴排序。 numpy.sort_complex(a)：针对复数排序。 搜索和计数 argmax(a ,axis,out)：返回数组中指定轴的最大值的索引。 nanargmax(a ,axis)：返回数组中指定轴的最大值的索引,忽略 NaN。 argmin(a ,axis,out)：返回数组中指定轴的最小值的索引。 nanargmin(a ,axis)：返回数组中指定轴的最小值的索引,忽略 NaN。 argwhere(a)：返回数组中非 0 元素的索引,按元素分组。 nonzero(a)：返回数组中非 0 元素的索引。 flatnonzero(a)：返回数组中非 0 元素的索引,并铺平。 where(条件,x,y)：根据指定条件,从指定行、列返回元素。 searchsorted(a,v ,side,sorter)：查找要插入元素以维持顺序的索引。 extract(condition,arr)：返回满足某些条件的数组的元素。 count_nonzero(a)：计算数组中非 0 元素的数量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Numpy使用教程（一）]]></title>
    <url>%2Fp%2F7dvvq%2F</url>
    <content type="text"><![CDATA[术语axis 对于二维数组，垂直为轴0，水平为轴1。许多操作可以沿着一个轴进行。 123456789&gt;&gt;&gt; x = np.arange(12).reshape(3,4)&gt;&gt;&gt; xarray([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&gt;&gt;&gt; x.sum(axis=0)array([12, 15, 18, 21])&gt;&gt;&gt; x.sum(axis=1)array([ 6, 22, 38]) broadcast Numpy可以对形状不匹配的数组执行操作 123456789&gt;&gt;&gt; np.array([2,3])+1array([3, 4])&gt;&gt;&gt; np.array([[2,3]])+1array([[3, 4]])&gt;&gt;&gt; np.array([[2,3]])+np.array([1,2])array([[3, 5]])&gt;&gt;&gt; np.array([[2],[3]])+np.array([1,2])array([[3, 4], [4, 5]]) 这个机制在便捷的同时可能会出现意料之外的结果，因此shape不确定时建议先reshape。 mask 布尔数组，用于选取元素 123456789&gt;&gt;&gt; x = np.arange(5)&gt;&gt;&gt; xarray([0, 1, 2, 3, 4])&gt;&gt;&gt; mask = (x &gt; 2)&gt;&gt;&gt; maskarray([False, False, False, True, True], dtype=bool)&gt;&gt;&gt; x[mask] = -1&gt;&gt;&gt; xarray([ 0, 1, 2, -1, -1]) 数值类型numpy 支持丰富的数值类型。 在数组里可以使用dtype=参数来指定数值类型。 使用.astype()方法进行数值类型转换，使用.dtype查看dtype属性。 多维数组的创建【参数说明】 order：{‘C’，’F’}，以行(C)或列(F)为主顺序。 创建ndarray的方法： 从列表、元组等转换 使用np.array将列表或元组转换为ndarray数组 使用np原生方法创建 arange在指定区间内创建一系列均匀间隔的值 linspace在指定区间内返回间隔均匀的值 ones用于快速创建数值全部为1的多维数组 zeros用于快速创建数值全部为0的多维数组 eye用于创建一个二维数组，其特点是k对角线上的值为1，其余值全为0 12345numpy.arange(start, stop, step, dtype=None)numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)numpy.ones(shape, dtype=None, order='C')numpy.zeros(shape, dtype=None, order='C')numpy.eye(N, M=None, k=0, dtype=&lt;type 'float'&gt;) 从已知数据创建 fromfile:从文本或二进制文件中构建多维数组 frombuffer, fromfunction, fromiter, fromstring等 多维数组的属性T：数组的转置，同.transpose() dtype：包含元素的数据类型 imag: 元素的虚部 rear: 元素的实部 size: 元素数 itemsize: 一个数组元素的字节数 nbytes: 元素总字节数 ndim: 数组的尺寸 shape: 数组维数组 数组的基本操作reshape numpy.reshape() 等效于 ndarray.reshape()。 1numpy.reshape(a, newshape) 重设形状, newshape为整数或元组。 ravel 1numpy.ravel(a, order='C') 将数组扁平化，变为一维数组。 moveaxis 1numpy.moveaxis(a, source, destination) 轴移动，可以将数组的轴移动到新的位置。 swapaxes 1numpy.swapaxes(a, axis1, axis2) 轴交换与轴移动的效果可以通过查看操作前后的shape变化来理解。 transpose 1numpy.transpose(a, axis=None) 类似于矩阵的转置。axis有值时替换轴。 atleast_xd 123numpy.atleast_1d()numpy.atleast_2d()numpy.atleast_3d() 维度改变，支持将输入数据直接视为x维。 类型转换 asarray(a，dtype，order)：将特定输入转换为数组。 asanyarray(a，dtype，order)：将特定输入转换为 ndarray。 asmatrix(data，dtype)：将特定输入转换为矩阵。 asfarray(a，dtype)：将特定输入转换为 float类型的数组。 asarray_chkfinite(a，dtype，order)：将特定输入转换为数组，检查 NaN 或 infs。 asscalar(a)：将大小为 1 的数组转换为标量。 concatenate 1numpy.concatenate((a1, a2, ...), axis=0) 数组连接。axis：指定连接轴。 堆叠 stack(arrays，axis)：沿着新轴连接数组的序列。 column_stack()：将 1 维数组作为列堆叠到 2 维数组中。 hstack()：按水平方向堆叠数组。 vstack()：按垂直方向堆叠数组。 dstack()：按深度方向堆叠数组。 拆分 split(ary，indices_or_sections，axis)：将数组拆分为多个子数组。 dsplit(ary，indices_or_sections)：按深度方向将数组拆分成多个子数组。 hsplit(ary，indices_or_sections)：按水平方向将数组拆分成多个子数组。 vsplit(ary，indices_or_sections)：按垂直方向将数组拆分成多个子数组。 delete 1numpy.delete(arr，obj，axis) 沿特定轴删除数组中的子数组。 insert 1numpy.insert(arr，obj，values，axis) 依据索引在特定轴之前插入值。 append 1numpy.append(arr，values，axis) 将值附加到数组的末尾，并返回 1 维数组。 resize 1numpy.resize(a，new_shape) 对数组尺寸进行重新设定。 【resize和reshape的区别】 reshape 在改变形状时，不会影响原数组，相当于对原数组做了一份拷贝。而 resize 则是对原数组执行操作。 翻转数组 fliplr(m)：左右翻转数组。 flipud(m)：上下翻转数组。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Scala语言初步]]></title>
    <url>%2Fp%2F7dmd9%2F</url>
    <content type="text"><![CDATA[两种类型的变量：val（常变量，类似于final）、var。Unit类型类似于void。 函数定义形式： 123def func(para:Type):Type=&#123;// do something&#125; 每个Scala表达式都有返回结果，函数最后一个表达式的值作为返回值（类似于Matlab） Scala没有i++和++i，用()访问数组而不是[]，使用[]指定泛型参数而不是&lt;&gt; Scala的foreach循环： 1234567// 第1种args.foreach(arg=&gt;println(arg))// 第2种args.foreach(println)// 第3种for(arg&lt;-args) println(arg) 如果一个方法只有一个参数，你可以不用.和()来调用这个方法。例如for循环： 1for(i &lt;- 0 to 2) &#123; &#125; 0 to 2等价于(0).to(2)，1+2等价于(1).+(2) （类似于Ruby） arr(1)等价于arr.apply(1)，arr(1)=x等价于arr.update(1, x) List是不可修改的序列，:::：连接两个List，::：向List里添加元素 （实际上是创建新List） Tuple与List都是不可修改的序列，Tuple可以包含不同类型的数据，List只能包含同类型的数据 使用._访问Tuple的元素 Set和Map分mutable（可变的）和immutable（不可变的）类型 定义Map： 1val map = Map(key1 -&gt; value1, key2 -&gt; value2) Scala使用_而不是*来引入多个类]]></content>
  </entry>
  <entry>
    <title><![CDATA[栈和队列——算法笔记]]></title>
    <url>%2Fp%2F7d4wx%2F</url>
    <content type="text"><![CDATA[链表链表可以方便地实现以下操作： 从表头添加元素 1234Node tmp = front;front = new Node();front.value = item; // item为添加的元素front.next = tmp; 考虑边界情况，当链表为空添加元素时的情况，需调整rear： 12if(rear==null) rear = front; 从表尾添加元素 1234Node tmp = rear;rear = new Node();rear.value = item; // item为添加的元素tmp.next = rear; 考虑边界情况，当链表为空添加元素时的情况，需调整front，同时舍弃tmp.next = rear; 12if(front==null) front = rear; 从表头删除元素 12T tmp = front.value;front = front.next; 考虑边界情况，当链表仅剩一个元素删除时，需调整rear： 12if(front==null) rear = null; 栈基于栈的特点，可以选择从表头添加元素，从表头删除元素，使用链表实现栈的代码如下： 123456789101112131415161718192021222324252627public class Stack&lt;T&gt; &#123; private class Node&#123; T value; Node next; &#125; private Node front; private int n; public void push(T item) &#123; Node tmp = front; front = new Node(); front.value = item; front.next = tmp; n++; &#125; public T pop() &#123; T tmp = front.value; front = front.next; n--; return tmp; &#125; public int size() &#123; return n; &#125; public boolean isEmpty() &#123; return front == null; &#125;&#125; 队列基于队列的特点，可以选择从表尾添加元素，从表头删除元素，使用链表实现队列的代码如下： 123456789101112131415161718192021222324252627282930313233public class Queue&lt;T&gt;&#123; private class Node&#123; T value; Node next; &#125; private Node front; private Node rear; private int n; public void enqueue(T item) &#123; Node tmp = rear; rear = new Node(); rear.value = item; if(tmp==null) front = rear; else tmp.next = rear; n++; &#125; public T dequeue() &#123; T tmp = front.value; front = front.next; if(front==null) rear = null; n--; return tmp; &#125; public int size() &#123; return n; &#125; public boolean isEmpty() &#123; return front == null; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[【实验楼】HBASE教程——学习笔记]]></title>
    <url>%2Fp%2F7czq8%2F</url>
    <content type="text"><![CDATA[HBase环境搭建与配置HBase解压即可使用。 【注意】伪分布模式下，HBase需要与Hadoop版本匹配，可以看HBase的lib里Hadoop的jar文件版本。 需要配置hbase-site.xml，可以使用自带的Zookeeper。 单机模式配置如下： 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file:///tmp/hbase-$&#123;user.name&#125;/hbase&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 伪分布模式配置如下： 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hbase-env.sh，需要设置JAVA_HOME和HBASE_MANAGES_ZK。使用自带的Zookeeper时，HBASE_MANAGES_ZK=true 启动HBase：start-hbase.sh，停止HBase：stop-hbase.sh 注意：若是伪分布模式，需要先启动HDFS。停止时先停HBase。 进入HBase Shell：hbase shell HBase基本操作显示帮助：help 显示状态：status 退出HBase：quit 创建新表：create &#39;表名&#39;, &#39;列族名&#39; 列举表信息：list、list &#39;表名&#39; 获取表描述：describe &#39;表名&#39; 删除表：删除表之前，先disable表，再drop表 检查表是否存在：exists &#39;表名&#39; 禁用表：disable &#39;表名&#39;，启用表：enable &#39;表名&#39; 向表中插入数据：put &#39;表名&#39;, &#39;行&#39;, &#39;列族:列&#39;, &#39;值&#39; 一次性扫描全表数据：scan &#39;表名&#39; 获取一行数据：get &#39;表名&#39;, &#39;行&#39; HBase应用程序开发org.apache.hadoop.hbase包下常用类： HBaseConfiguration HBase配置 HColumnDescriptor 列族描述符，指定列族相关信息 HTableDescriptor 表名描述符，指定表相关信息 org.apache.hadoop.hbase.client包下常用类： HBaseAdmin HBase管理（判断表是否存在、创建表等） HTable 表 Get 获取数据 Put 添加数据 Scan Result ResultScanner 创建表： 1234HBaseAdmin admin = new HBaseAdmin(conf);HTableDescriptor tabDesc = new HTableDescriptor(tableName);tabDesc.addFamily(new HColumnDescriptor(columnFamily));admin.createTable(tabDesc); 1234Table tab = new HTable(conf, tableName);Put p = new Put(Bytes.toBytes(row));p.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(data));tab.put(p); 获取、扫描数据： 12345678910HTable tab = new HTable(conf, tableName);// getGet g = new Get(Bytes.toBytes(row));Result r= tab.get(g);// scanScan s = new Scan();ResultScanner rs = tab.getScanner(s);for(Result rst:rs)&#123; ; // do something&#125; 删除表： 1234if(admin.tableExists(tableName))&#123; admin.disableTable(tableName); admin.deleteTable(tableName);&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python项目：扇贝网小组查卡助手]]></title>
    <url>%2Fp%2F6vof6%2F</url>
    <content type="text"><![CDATA[扇贝网是一个非常棒的英语学习网站，大家还可以加入一些小组，一起交流学习、共同进步。但是，小组管理起来非常辛苦，尤其是在0点前踢出不打卡的成员，因此考虑利用程序来实现小组查卡自动化。 登录 操作扇贝网登录 URLhttp://www.shanbay.com/accounts/login/ 方式POST 数据csrfmiddlewaretokenCSRF令牌 username用户名 password密码 CSRF令牌存在于Cookie中，我们需要先以GET方式访问该URL，就能取到CSRF令牌了。 1234567891011121314151617181920# -*- coding: utf-8 -*-import requestsclass Shanbay(): def __init__(self, username, password): self.request = requests.Session() self.username = username self.password = password def login(self): url = 'http://www.shanbay.com/accounts/login/' r = self.request.get(url) csrftoken = r.cookies['csrftoken'] data = &#123; 'csrfmiddlewaretoken': csrftoken, 'username': self.username, 'password': self.password, &#125; return self.request.post(url, data=data).ok 成员管理如果我们获取小组管理后台所有组员的信息，比较费时间。考虑实际需求，不妨仅获取当天未打卡的组员的信息，这样能大大提高查卡效率。 踢人需要data-id，这个在小组管理后台页面就能获取到。但是，如果我们想发站内短信，就需要username，而username在小组管理后台页面里是没有的，这个需要查看个人打卡日记。 从个人打卡日记不仅能看到username，还能看到该贝友入组后最近已连续有多少天未打卡（这往往也是组规限定的内容）等等。 操作踢人 URLhttp://www.shanbay.com/api/v1/team/member/ 方式PUT 数据action动作（'dispel'） idsdata-id 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# -*- coding: utf-8 -*-from bs4 import BeautifulSoupfrom Journal import Journalimport reclass Domain(): def __init__(self, shanbay): self.shanbay = shanbay self.request = shanbay.request def get_not_checked_members(self): ''' data_id : 踢人时需要data_id role : 身份标识 nickname : 昵称 user_id : 发短信时需要user_id username : 用户名 points : 贡献值 days : 组龄 rate : 打卡率 checked_yesterday: 昨天是否打卡 checked : 今天是否打卡 off_dyas : 入组后最近连续未打卡天数 ''' members = [] for page in range(1, 48): html = self.request.get('http://www.shanbay.com/team/manage/?t=checkin_today&amp;page=%d' % page).text soup = BeautifulSoup(html, 'html5lib') for member in soup.find_all('tr', class_='member'): checked = member.find_all(class_='checked')[1].find('span').text.strip() == '已打卡' if checked: break days = int(member.find(class_='days').text) user_id = re.findall('\d+', member.find(class_='user').find('a')['href'])[0] user = Journal(shanbay=self.shanbay, user_id=user_id) checked_yesterday = member.find_all(class_='checked')[0].find('span').text.strip() == '已打卡' if checked_yesterday: off_days = 1 else: off_days = user.get_off_days(days) data = &#123; 'data_id':member['data-id'], 'role':member['role'], 'nickname':member.find(class_='user').find('a').text, 'user_id':user_id, 'username':user.get_username(), 'points':int(member.find(class_='points').text), 'days':days, 'rate':float(member.find(class_='rate').find('span').text[:-2]), 'checked_yesterday':checked_yesterday, 'checked':checked, 'off_dyas':off_days &#125; members.append(data) else: continue break return members def dismiss(self, data_ids): url = 'http://www.shanbay.com/api/v1/team/member/' data = &#123; 'action': 'dispel', &#125; data['ids'] = ','.join(map(str, data_ids)) r = self.request.put(url, data=data) return r.json()['msg'] == "SUCCESS" （这里用到了Python跳出两层循环的技巧^_^） 打卡日记通过打卡日记，我们可以获得一些基本信息，例如：用户名、最近连续未打卡天数等。 123456789101112131415161718192021222324# -*- coding: utf-8 -*-from bs4 import BeautifulSoupimport reimport datetimeimport timeclass Journal(): def __init__(self, shanbay, user_id): self.shanbay = shanbay self.request = shanbay.request self.user_id = user_id self.soup = self.__get_journal_soup() def __get_journal_soup(self): html = self.request.get('http://www.shanbay.com/checkin/user/%s/' % self.user_id).text return BeautifulSoup(html) def get_username(self): return re.findall(u'(\w+)\s*的日记', self.soup.find_all(class_='page-header')[0].find('h2').text)[0] def get_off_days(self, days=0): pass 站内短信 操作发送站内短信 URLhttp://www.shanbay.com/api/v1/message/ 方式POST 数据recipient收件人（username） subject标题 body内容 csrfmiddlewaretokenCSRF令牌 1234567891011121314151617# -*- coding: utf-8 -*-class Message(): def __init__(self, shanbay): self.shanbay = shanbay self.request = shanbay.request def send_msg(self,recipient, subject, body): url = 'http://www.shanbay.com/api/v1/message/' data = &#123; 'recipient': recipient, 'subject': subject, 'body': body, 'csrfmiddlewaretoken': self.request.cookies['csrftoken'] &#125; return self.request.post(url, data=data).ok 小组管理 操作设定加组条件 URLhttp://www.shanbay.com/team/setqualification/{team_id} 方式POST 数据value天数 kind类型 condition条件 team小组id csrfmiddlewaretokenCSRF令牌 若需要在小组发帖或回帖，需要forum_id而不是小组id，而forum_id可以通过小组主页找到。 操作发帖 URLhttp://www.shanbay.com/api/v1/forum/{forum_id}/thread/ 方式post 数据title标题 body内容 csrfmiddlewaretokenCSRF令牌 操作回帖 URLhttp://www.shanbay.com/api/v1/forum/thread/{post_id}/post/ 方式POST 数据body内容 csrfmiddlewaretokenCSRF令牌 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- coding: utf-8 -*-from bs4 import BeautifulSoupclass Team(): def __init__(self, shanbay, team_id): self.shanbay = shanbay self.request = shanbay.request self.team_id = team_id self.forum_id = self.__get_forum_id() def set_join_limit(self, days, kind=2, condition='&gt;='): url = 'http://www.shanbay.com/team/setqualification/%s' % self.team_id data = &#123; 'value': days, 'kind': kind, 'condition': condition, 'team': self.team_id, 'csrfmiddlewaretoken': self.request.cookies['csrftoken'] &#125; r = self.request.post(url, data=data) return 'http://www.shanbay.com/referral/invite/?kind=team' == r.url def __get_forum_id(self): html = self.request.get('http://www.shanbay.com/team/detail/%s/' % str(self.teamId)).text soup = BeautifulSoup(html) return soup.find(id='forum_id')['value'] def new_post(self, title, content): url = 'http://www.shanbay.com/api/v1/forum/%s/thread/' % self.forum_id data = &#123; 'title': title, 'body': content, 'csrfmiddlewaretoken': self.request.cookies['csrftoken'] &#125; return self.request.post(url, data=data).json() def reply_post(self, post_id, content): url = 'http://www.shanbay.com/api/v1/forum/thread/%s/post/' % post_id data = &#123; 'body': content, 'csrfmiddlewaretoken': self.request.cookies.get('csrftoken') &#125; return self.request.post(url, data=data).json()]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu搭建Ruby on Rails环境]]></title>
    <url>%2Fp%2F6v913%2F</url>
    <content type="text"><![CDATA[安装Ruby由于Ubuntu的apt包管理器的ruby版本过旧，故考虑从源码编译安装。这里以安装ruby2.3.0为例： 12345678sudo apt-get install build-essential zlib1g-dev libssl-dev libreadline6-dev libyaml-devcd /tmpwget https://cache.ruby-lang.org/pub/ruby/2.3/ruby-2.3.0.tar.gztar -xvzf ruby-2.3.0.tar.gzcd ruby-2.3.0/./configuremakesudo make install 安装完成后，我们可以查看其版本： 12$ ruby -vruby 2.3.0p0 (2015-12-25 revision 53290) [i686-linux] 安装sqlite31sudo apt-get install sqlite3 libsqlite3-dev 安装Rails由于GFW的缘故，ruby默认的gem源rubygems.org无法访问，故需要先换源。 查看当前的gem源： 1234$ gem sources -l*** CURRENT SOURCES ***https://rubygems.org/ 换源： 12345678$ gem sources -r https://rubygems.org/https://rubygems.org/ removed from sources$ gem sources -a https://ruby.taobao.org/https://ruby.taobao.org/ added to sources$ gem sources -l*** CURRENT SOURCES ***https://ruby.taobao.org/ 安装Rails： 1sudo gem install rails 安装完成后查看其版本： 12$ rails --versionRails 4.2.5.2 修改Gemfile编辑Gemfile： 1sudo vi /usr/local/lib/ruby/gems/2.3.0/gems/railties-4.2.5.2/lib/rails/generators/rails/app/templates/Gemfile 将第一行 1source 'https://rubygems.org' 改为： 1source &apos;https://ruby.taobao.org/&apos; 安装JavaScript 运行时这里选择安装NodeJS： 1sudo apt-get install nodejs 建立Rails工程1rails new demo 进入文件夹，启动服务器： 12cd demo/rails server]]></content>
      <tags>
        <tag>Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫入门案例：获取百词斩已学单词列表]]></title>
    <url>%2Fp%2F6sjd1%2F</url>
    <content type="text"><![CDATA[百词斩是一款很不错的单词记忆APP，在学习过程中，它会记录你所学的每个单词及你答错的次数，通过此列表可以很方便地找到自己在记忆哪些单词时总是反复出错记不住。我们来用Python来爬取这些信息，同时学习Python爬虫基础。 首先来到百词斩网站：http://www.baicizhan.com/login 这个网站是需要登录的，不过还好没验证码，我们可以先看下在登录过程中浏览器POST了哪些数据。打开浏览器开发工具（F12），以Chrome浏览器为例，记录登录过程中浏览器的Network情况： 我们可以发现，在登录过程中，浏览器向http://www.baicizhan.com/login以POST方式提交了数据。提交了什么数据呢？我们可以在下面的Form Data里看到。 其中，email是用户名，raw_pwd就是密码，这里的数据是需要经过URL编码的，我们可以点view URL encoded查看编码后的样子。URL编码需要urllib库。 在请求头（Request Headers）部分，我们还看到了Cookie。因此，我们还需要cookie库，来处理我们的Cookie。 12345678910111213import urllibimport urllib2import cookielibemail = 'your_email' pwd = 'your_password' data = &#123;'email':email,'raw_pwd':pwd&#125;post_data = urllib.urlencode(data)opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookielib.CookieJar()))response = opener.open('http://www.baicizhan.com/login', post_data)print(response.read()) 这样，我们可以发现，打印的是登录后的页面源码，这说明我们成功实现了登录。 接着，我们来分析下单词列表的页面：http://www.baicizhan.com/user/words/list 当我们点击页码时，实际上是发送了GET请求。然后我们看Response，发现是个json，我们解析下看看（可以到http://www.json.cn/在线解析json） 如果要在Python中解析json，我们需要json库。我们打印下前两页的单词看看： 1234567891011121314151617181920import urllib2import cookielibimport urllibimport jsonemail = 'your_email' pwd = 'your_password' data = &#123;'email':email,'raw_pwd':pwd&#125;post_data = urllib.urlencode(data)opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookielib.CookieJar()))opener.open('http://www.baicizhan.com/login', post_data)for i in range(1, 3): content = json.loads(opener.open("http://www.baicizhan.com/user/all_done_words_list?page=%s"%i).read()) for word in content["list"]: print word["word"] print word["word_meaning"].strip() print word["wrong_times"] 这样，我们就能打印出前两页的单词以及释义、错误次数。 至于要把所有已学单词都获取到，只需要稍作修改即可，之后我们便能把这些数据存储进行一些后续的处理。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Ubuntu下Chrome浏览器网页中文字体混乱]]></title>
    <url>%2Fp%2F6si5c%2F</url>
    <content type="text"><![CDATA[在Ubuntu下使用Chrome浏览器时碰到了网页中文字体混乱的现象： 黑体和楷体混杂，看起来非常不美观。 这是由于许多网页并没有指定字体，然后浏览器将调用系统默认字体配置。 首先，安装文泉驿字体： 1sudo apt-get install ttf-wqy* 编辑字体设置 1sudo gedit /etc/fonts/conf.avail/69-language-selector-zh-cn.conf 可以设置字体的优先级，个人比较喜欢文泉驿正黑（WenQuanYi Zen Hei） 最后，重启电脑。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[墙内搭建Android开发环境]]></title>
    <url>%2Fp%2F6s1gi%2F</url>
    <content type="text"><![CDATA[提到搭建Android开发环境，一般给出的方案是在Eclipse输入 https://dl-ssl.google.com/android/eclipse 在线安装，或者下载Android Studio。然而，由于GFW，这些方案实现起来往往并不容易。 因此，推荐一个网站：http://www.androiddevtools.cn/ 里面整理了Android Studio、ADT、SDK等各种Android开发相关工具，大家直接下载即可。 至于具体的Android环境搭建过程，网上教程非常多，在此不作赘述。 何时Google才能归来呢？]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下编译lua源码]]></title>
    <url>%2Fp%2F6s16d%2F</url>
    <content type="text"><![CDATA[lua是门非常小巧的脚本语言，官网：lua官网。下载其源码后，解压： 1tar -zxvf lua-5.3.1.tar.gz 进入目录并make： 12cd lua-5.3.1/make linux 报错： 12lua.c:80:31: fatal error: readline/readline.h: No such file or directory #include &lt;readline/readline.h&gt; 安装缺少的依赖： 12sudo apt-get install build-essentialsudo apt-get install libreadline-gplv2-dev 重新编译： 12make linuxsudo make install 完成！ 12lua-5.3.1$ luaLua 5.3.1 Copyright (C) 1994-2015 Lua.org, PUC-Rio 附加说明 网上有很多说要安装libreadline5-dev，在尝试安装时提示： 123456Package libreadline5-dev is not available, but is referred to by another package.This may mean that the package is missing, has been obsoleted, oris only available from another sourceHowever the following packages replace it: libreadline-gplv2-dev:i386 lib64readline-gplv2-dev:i386 libreadline-gplv2-dev 所以选择安装libreadline-gplv2-dev]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Lua</tag>
      </tags>
  </entry>
</search>
